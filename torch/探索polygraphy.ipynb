{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polygraphy 功能探索\n",
    "\n",
    "看起来 Polygraphy 的功能很强大, 探索下部分功能.\n",
    "\n",
    "[Polygraphy github](https://github.com/NVIDIA/TensorRT/tree/main/tools/Polygraphy)\n",
    "\n",
    "Polygraphy 里面既有 cli 工具, 也有 python api, 这里主要使用命令行工具."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 安装\n",
    "\n",
    "跳过安装的部分, 当前镜像里有, 先不看了, 专注于使用.\n",
    "\n",
    "```bash\n",
    "python -m pip install colored polygraphy --extra-index-url https://pypi.ngc.nvidia.com\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: polygraphy [-h] [-v]\n",
      "                  {run,convert,inspect,surgeon,template,debug,data} ...\n",
      "\n",
      "Polygraphy: A Deep Learning Debugging Toolkit\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -v, --version         show program's version number and exit\n",
      "\n",
      "Tools:\n",
      "  {run,convert,inspect,surgeon,template,debug,data}\n",
      "    run                 Run inference and compare results across backends.\n",
      "    convert             Convert models to other formats.\n",
      "    inspect             View information about various types of files.\n",
      "    surgeon             Modify ONNX models.\n",
      "    template            [EXPERIMENTAL] Generate template files.\n",
      "    debug               [EXPERIMENTAL] Debug model accuracy issues.\n",
      "    data                Manipulate input and output data generated by other\n",
      "                        Polygraphy subtools.\n"
     ]
    }
   ],
   "source": [
    "!polygraphy -h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# polygraphy run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: polygraphy run [-h] [-v] [-q] [--silent]\n",
      "                      [--log-format {timestamp,line-info,no-colors} [{timestamp,line-info,no-colors} ...]]\n",
      "                      [--log-file LOG_FILE]\n",
      "                      [--model-type {frozen,keras,ckpt,onnx,engine,uff,trt-network-script,caffe}]\n",
      "                      [--input-shapes INPUT_SHAPES [INPUT_SHAPES ...]]\n",
      "                      [--ckpt CKPT] [--tf-outputs TF_OUTPUTS [TF_OUTPUTS ...]]\n",
      "                      [--save-pb SAVE_PB]\n",
      "                      [--save-tensorboard SAVE_TENSORBOARD] [--freeze-graph]\n",
      "                      [--tftrt] [--minimum-segment-size MINIMUM_SEGMENT_SIZE]\n",
      "                      [--dynamic-op]\n",
      "                      [--gpu-memory-fraction GPU_MEMORY_FRACTION]\n",
      "                      [--allow-growth] [--xla] [--save-timeline SAVE_TIMELINE]\n",
      "                      [--opset OPSET] [--no-const-folding]\n",
      "                      [--save-onnx SAVE_ONNX]\n",
      "                      [--save-external-data [SAVE_EXTERNAL_DATA]]\n",
      "                      [--external-data-size-threshold EXTERNAL_DATA_SIZE_THRESHOLD]\n",
      "                      [--no-save-all-tensors-to-one-file] [--shape-inference]\n",
      "                      [--external-data-dir LOAD_EXTERNAL_DATA]\n",
      "                      [--onnx-outputs ONNX_OUTPUTS [ONNX_OUTPUTS ...]]\n",
      "                      [--onnx-exclude-outputs ONNX_EXCLUDE_OUTPUTS [ONNX_EXCLUDE_OUTPUTS ...]]\n",
      "                      [--trt-min-shapes TRT_MIN_SHAPES [TRT_MIN_SHAPES ...]]\n",
      "                      [--trt-opt-shapes TRT_OPT_SHAPES [TRT_OPT_SHAPES ...]]\n",
      "                      [--trt-max-shapes TRT_MAX_SHAPES [TRT_MAX_SHAPES ...]]\n",
      "                      [--tf32] [--fp16] [--int8] [--strict-types]\n",
      "                      [--sparse-weights] [--workspace BYTES]\n",
      "                      [--calibration-cache CALIBRATION_CACHE]\n",
      "                      [--calib-base-cls CALIBRATION_BASE_CLASS]\n",
      "                      [--quantile QUANTILE]\n",
      "                      [--regression-cutoff REGRESSION_CUTOFF]\n",
      "                      [--timing-cache TIMING_CACHE]\n",
      "                      [--tactic-replay TACTIC_REPLAY | --save-tactics SAVE_TACTICS | --load-tactics LOAD_TACTICS]\n",
      "                      [--tactic-sources [TACTIC_SOURCES [TACTIC_SOURCES ...]]]\n",
      "                      [--trt-config-script TRT_CONFIG_SCRIPT]\n",
      "                      [--trt-config-func-name TRT_CONFIG_FUNC_NAME]\n",
      "                      [--trt-safety-restricted] [--use-dla]\n",
      "                      [--allow-gpu-fallback] [--plugins PLUGINS [PLUGINS ...]]\n",
      "                      [--explicit-precision]\n",
      "                      [--trt-outputs TRT_OUTPUTS [TRT_OUTPUTS ...]]\n",
      "                      [--trt-exclude-outputs TRT_EXCLUDE_OUTPUTS [TRT_EXCLUDE_OUTPUTS ...]]\n",
      "                      [--trt-network-func-name TRT_NETWORK_FUNC_NAME]\n",
      "                      [--save-engine SAVE_ENGINE] [-p PREPROCESSOR]\n",
      "                      [--uff-order UFF_ORDER] [--batch-size SIZE]\n",
      "                      [--model CAFFE_MODEL] [--save-uff] [--seed SEED]\n",
      "                      [--val-range VAL_RANGE [VAL_RANGE ...]]\n",
      "                      [--int-min INT_MIN] [--int-max INT_MAX]\n",
      "                      [--float-min FLOAT_MIN] [--float-max FLOAT_MAX]\n",
      "                      [--iterations NUM]\n",
      "                      [--load-inputs LOAD_INPUTS [LOAD_INPUTS ...]]\n",
      "                      [--data-loader-script DATA_LOADER_SCRIPT]\n",
      "                      [--data-loader-func-name DATA_LOADER_FUNC_NAME]\n",
      "                      [--warm-up NUM] [--use-subprocess]\n",
      "                      [--save-inputs SAVE_INPUTS]\n",
      "                      [--save-outputs SAVE_RESULTS] [--no-shape-check]\n",
      "                      [--rtol RTOL [RTOL ...]] [--atol ATOL [ATOL ...]]\n",
      "                      [--validate] [--fail-fast] [--top-k TOP_K [TOP_K ...]]\n",
      "                      [--check-error-stat CHECK_ERROR_STAT [CHECK_ERROR_STAT ...]]\n",
      "                      [--load-outputs LOAD_RESULTS [LOAD_RESULTS ...]]\n",
      "                      [--gen GEN_SCRIPT] [--trt] [--trt-legacy] [--tf]\n",
      "                      [--onnxrt] [--pluginref]\n",
      "                      [model_file]\n",
      "\n",
      "Run inference and compare results across backends.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --gen GEN_SCRIPT, --gen-script GEN_SCRIPT\n",
      "                        Path to save a generated Python script, that will do\n",
      "                        exactly what `run` would. When this option is enabled,\n",
      "                        `run` will just save the script and exit. Use `-` to\n",
      "                        print the script to the standard output\n",
      "\n",
      "Logging:\n",
      "  Options for logging and debug output\n",
      "\n",
      "  -v, --verbose         Increase logging verbosity. Specify multiple times for\n",
      "                        higher verbosity\n",
      "  -q, --quiet           Decrease logging verbosity. Specify multiple times for\n",
      "                        lower verbosity\n",
      "  --silent              Disable all output\n",
      "  --log-format {timestamp,line-info,no-colors} [{timestamp,line-info,no-colors} ...]\n",
      "                        Format for log messages: {{'timestamp': Include\n",
      "                        timestamp, 'line-info': Include file and line number,\n",
      "                        'no-colors': Disable colors}}\n",
      "  --log-file LOG_FILE   Path to a file where Polygraphy logging output should\n",
      "                        be written. This will not include logging output from\n",
      "                        dependencies, like TensorRT or ONNX-Runtime.\n",
      "\n",
      "Model:\n",
      "  Options for the model\n",
      "\n",
      "  model_file            Path to the model\n",
      "  --model-type {frozen,keras,ckpt,onnx,engine,uff,trt-network-script,caffe}\n",
      "                        The type of the input model: {{'frozen': TensorFlow\n",
      "                        frozen graph, 'keras': Keras model, 'ckpt': TensorFlow\n",
      "                        checkpoint directory, 'onnx': ONNX model, 'engine':\n",
      "                        TensorRT engine, 'trt-network-script': A Python script\n",
      "                        that defines a `load_network` function that takes no\n",
      "                        arguments and returns a TensorRT Builder, Network, and\n",
      "                        optionally Parser, 'uff': UFF file [deprecated],\n",
      "                        'caffe': Caffe prototxt [deprecated]}}\n",
      "  --input-shapes INPUT_SHAPES [INPUT_SHAPES ...], --inputs INPUT_SHAPES [INPUT_SHAPES ...]\n",
      "                        Model input(s) and their shape(s). Used to determine\n",
      "                        shapes to use while generating input data for\n",
      "                        inference. Format: --input-shapes <name>:<shape>. For\n",
      "                        example: --input-shapes image:[1,3,224,224]\n",
      "                        other_input:[10]\n",
      "\n",
      "TensorFlow Loader:\n",
      "  Options for TensorFlow Loader\n",
      "\n",
      "  --ckpt CKPT           [EXPERIMENTAL] Name of the checkpoint to load.\n",
      "                        Required if the `checkpoint` file is missing. Should\n",
      "                        not include file extension (e.g. to load `model.meta`\n",
      "                        use `--ckpt=model`)\n",
      "  --tf-outputs TF_OUTPUTS [TF_OUTPUTS ...]\n",
      "                        Name(s) of TensorFlow output(s). Using '--tf-outputs\n",
      "                        mark all' indicates that all tensors should be used as\n",
      "                        outputs\n",
      "  --save-pb SAVE_PB     Path to save the TensorFlow frozen graphdef\n",
      "  --save-tensorboard SAVE_TENSORBOARD\n",
      "                        [EXPERIMENTAL] Path to save a TensorBoard\n",
      "                        visualization\n",
      "  --freeze-graph        [EXPERIMENTAL] Attempt to freeze the graph\n",
      "\n",
      "TensorFlow-TensorRT:\n",
      "  [UNTESTED] Options for TensorFlow-TensorRT Integration\n",
      "\n",
      "  --tftrt, --use-tftrt  [UNTESTED] Enable TF-TRT integration\n",
      "  --minimum-segment-size MINIMUM_SEGMENT_SIZE\n",
      "                        Minimum length of a segment to convert to TensorRT\n",
      "  --dynamic-op          Enable dynamic mode (defers engine build until\n",
      "                        runtime)\n",
      "\n",
      "TensorFlow Session Configuration:\n",
      "  Options for the TensorFlow Session Configuration\n",
      "\n",
      "  --gpu-memory-fraction GPU_MEMORY_FRACTION\n",
      "                        Maximum percentage of GPU memory TensorFlow can\n",
      "                        allocate per process\n",
      "  --allow-growth        Allow GPU memory allocated by TensorFlow to grow\n",
      "  --xla                 [EXPERIMENTAL] Attempt to run graph with xla\n",
      "\n",
      "TensorFlow Runner:\n",
      "  Options for TensorFlow Inference\n",
      "\n",
      "  --save-timeline SAVE_TIMELINE\n",
      "                        [EXPERIMENTAL] Directory to save timeline JSON files\n",
      "                        for profiling inference (view at chrome://tracing)\n",
      "\n",
      "TensorFlow-ONNX Loader:\n",
      "  Options for TensorFlow-ONNX conversion\n",
      "\n",
      "  --opset OPSET         Opset to use when converting to ONNX\n",
      "  --no-const-folding    Do not fold constants in the TensorFlow graph prior to\n",
      "                        conversion\n",
      "\n",
      "ONNX Save Options:\n",
      "  Options for saving ONNX models\n",
      "\n",
      "  --save-onnx SAVE_ONNX, --save-onnx SAVE_ONNX\n",
      "                        Path to save the ONNX model\n",
      "  --save-external-data [SAVE_EXTERNAL_DATA]\n",
      "                        Whether to save weight data in external file(s). To\n",
      "                        use a non-default path, supply the desired path as an\n",
      "                        argument. This is always a relative path; external\n",
      "                        data is always written to the same directory as the\n",
      "                        model.\n",
      "  --external-data-size-threshold EXTERNAL_DATA_SIZE_THRESHOLD\n",
      "                        The size threshold, in bytes, above which tensor data\n",
      "                        will be stored in the external file. Tensors smaller\n",
      "                        that this threshold will remain in the ONNX file.\n",
      "                        Optionally, use a `K`, `M`, or `G` suffix to indicate\n",
      "                        KiB, MiB, or GiB respectively.For example,\n",
      "                        `--external-data-size-threshold=16M` is equivalent to\n",
      "                        `--external-data-size-threshold=16777216`Has no effect\n",
      "                        if `--save-external-data` is not set\n",
      "  --no-save-all-tensors-to-one-file\n",
      "                        Do not save all tensors to a single file when saving\n",
      "                        external data. Has no effect if `--save-external-data`\n",
      "                        is not set\n",
      "\n",
      "ONNX Shape Inference:\n",
      "  Options for ONNX Shape Inference\n",
      "\n",
      "  --shape-inference     Enable ONNX shape inference when loading the model\n",
      "\n",
      "ONNX Loader:\n",
      "  Options for the ONNX Loader\n",
      "\n",
      "  --external-data-dir LOAD_EXTERNAL_DATA, --load-external-data LOAD_EXTERNAL_DATA, --ext LOAD_EXTERNAL_DATA\n",
      "                        Path to a directory containing external data for the\n",
      "                        model. Generally, this is only required if the\n",
      "                        external data is not stored in the model directory.\n",
      "  --onnx-outputs ONNX_OUTPUTS [ONNX_OUTPUTS ...]\n",
      "                        Name(s) of ONNX tensor(s) to mark as output(s). Using\n",
      "                        the special value 'mark all' indicates that all\n",
      "                        tensors should be used as outputs\n",
      "  --onnx-exclude-outputs ONNX_EXCLUDE_OUTPUTS [ONNX_EXCLUDE_OUTPUTS ...]\n",
      "                        [EXPERIMENTAL] Name(s) of ONNX output(s) to unmark as\n",
      "                        outputs.\n",
      "\n",
      "TensorRT Builder Configuration:\n",
      "  Options for TensorRT Builder Configuration\n",
      "\n",
      "  --trt-min-shapes TRT_MIN_SHAPES [TRT_MIN_SHAPES ...]\n",
      "                        The minimum shapes the optimization profile(s) will\n",
      "                        support. Specify this option once for each profile. If\n",
      "                        not provided, inference-time input shapes are used.\n",
      "                        Format: --trt-min-shapes <input0>:[D0,D1,..,DN] ..\n",
      "                        <inputN>:[D0,D1,..,DN]\n",
      "  --trt-opt-shapes TRT_OPT_SHAPES [TRT_OPT_SHAPES ...]\n",
      "                        The shapes for which the optimization profile(s) will\n",
      "                        be most performant. Specify this option once for each\n",
      "                        profile. If not provided, inference-time input shapes\n",
      "                        are used. Format: --trt-opt-shapes\n",
      "                        <input0>:[D0,D1,..,DN] .. <inputN>:[D0,D1,..,DN]\n",
      "  --trt-max-shapes TRT_MAX_SHAPES [TRT_MAX_SHAPES ...]\n",
      "                        The maximum shapes the optimization profile(s) will\n",
      "                        support. Specify this option once for each profile. If\n",
      "                        not provided, inference-time input shapes are used.\n",
      "                        Format: --trt-max-shapes <input0>:[D0,D1,..,DN] ..\n",
      "                        <inputN>:[D0,D1,..,DN]\n",
      "  --tf32                Enable tf32 precision in TensorRT\n",
      "  --fp16                Enable fp16 precision in TensorRT\n",
      "  --int8                Enable int8 precision in TensorRT. If calibration is\n",
      "                        required but no calibration cache is provided, this\n",
      "                        option will cause TensorRT to run int8 calibration\n",
      "                        using the Polygraphy data loader to provide\n",
      "                        calibration data.\n",
      "  --strict-types        Enable strict types in TensorRT, forcing it to choose\n",
      "                        tactics based on the layer precision set, even if\n",
      "                        another precision is faster.\n",
      "  --sparse-weights      Enable optimizations for sparse weights in TensorRT\n",
      "  --workspace BYTES     Amount of memory, in bytes, to allocate for the\n",
      "                        TensorRT builder's workspace. Optionally, use a `K`,\n",
      "                        `M`, or `G` suffix to indicate KiB, MiB, or GiB\n",
      "                        respectively.For example, `--workspace=16M` is\n",
      "                        equivalent to `--workspace=16777216`\n",
      "  --calibration-cache CALIBRATION_CACHE\n",
      "                        Path to load/save a calibration cache. Used to store\n",
      "                        calibration scales to speed up the process of int8\n",
      "                        calibration. If the provided path does not yet exist,\n",
      "                        int8 calibration scales will be calculated and written\n",
      "                        to it during engine building. If the provided path\n",
      "                        does exist, it will be read and int8 calibration will\n",
      "                        be skipped during engine building.\n",
      "  --calib-base-cls CALIBRATION_BASE_CLASS, --calibration-base-class CALIBRATION_BASE_CLASS\n",
      "                        The name of the calibration base class to use. For\n",
      "                        example, 'IInt8MinMaxCalibrator'.\n",
      "  --quantile QUANTILE   The quantile to use for IInt8LegacyCalibrator. Has no\n",
      "                        effect for other calibrator types.\n",
      "  --regression-cutoff REGRESSION_CUTOFF\n",
      "                        The regression cutoff to use for\n",
      "                        IInt8LegacyCalibrator. Has no effect for other\n",
      "                        calibrator types.\n",
      "  --timing-cache TIMING_CACHE\n",
      "                        Path to load/save tactic timing cache. Used to cache\n",
      "                        tactic timing information to speed up the engine\n",
      "                        building process. Existing caches will be appended to\n",
      "                        with any new timing information gathered.\n",
      "  --tactic-replay TACTIC_REPLAY\n",
      "                        [DEPRECATED - use --load/save-tactics] Path to\n",
      "                        load/save a tactic replay file. Used to record and\n",
      "                        replay tactics selected by TensorRT to provide\n",
      "                        deterministic engine builds. If the provided path does\n",
      "                        not yet exist, tactics will be recorded and written to\n",
      "                        it. If the provided path does exist, it will be read\n",
      "                        and used to replay previously recorded tactics.\n",
      "  --save-tactics SAVE_TACTICS\n",
      "                        Path to save a tactic replay file. Tactics selected by\n",
      "                        TensorRT will be recorded and stored at this location.\n",
      "  --load-tactics LOAD_TACTICS\n",
      "                        Path to load a tactic replay file. The tactics\n",
      "                        specified in the file will be used to override\n",
      "                        TensorRT's default selections.\n",
      "  --tactic-sources [TACTIC_SOURCES [TACTIC_SOURCES ...]]\n",
      "                        Tactic sources to enable. This controls which\n",
      "                        libraries (e.g. cudnn, cublas, etc.) TensorRT is\n",
      "                        allowed to load tactics from. Values come from the\n",
      "                        names of the values in the trt.TacticSource enum, and\n",
      "                        are case-insensitive. If no arguments are provided,\n",
      "                        e.g. '--tactic-sources', then all tactic sources are\n",
      "                        disabled.\n",
      "  --trt-config-script TRT_CONFIG_SCRIPT\n",
      "                        Path to a Python script that defines a function that\n",
      "                        creates a TensorRT IBuilderConfig. The function should\n",
      "                        take a builder and network as parameters and return a\n",
      "                        TensorRT builder configuration. When this option is\n",
      "                        specified, all other config arguments are ignored.\n",
      "  --trt-config-func-name TRT_CONFIG_FUNC_NAME\n",
      "                        When using a trt-config-script, this specifies the\n",
      "                        name of the function that creates the config. Defaults\n",
      "                        to `load_config`.\n",
      "  --trt-safety-restricted\n",
      "                        Enable safety scope checking in TensorRT\n",
      "  --use-dla             [EXPERIMENTAL] Use DLA as the default device type\n",
      "  --allow-gpu-fallback  [EXPERIMENTAL] Allow layers unsupported on the DLA to\n",
      "                        fall back to GPU. Has no effect if --dla is not set.\n",
      "\n",
      "TensorRT Plugin Loader:\n",
      "  Options for TensorRT Plugin Loader\n",
      "\n",
      "  --plugins PLUGINS [PLUGINS ...]\n",
      "                        Path(s) of plugin libraries to load\n",
      "\n",
      "TensorRT Network Loader:\n",
      "  Options for TensorRT Network Loader\n",
      "\n",
      "  --explicit-precision  Enable explicit precision mode\n",
      "  --trt-outputs TRT_OUTPUTS [TRT_OUTPUTS ...]\n",
      "                        Name(s) of TensorRT output(s). Using '--trt-outputs\n",
      "                        mark all' indicates that all tensors should be used as\n",
      "                        outputs\n",
      "  --trt-exclude-outputs TRT_EXCLUDE_OUTPUTS [TRT_EXCLUDE_OUTPUTS ...]\n",
      "                        [EXPERIMENTAL] Name(s) of TensorRT output(s) to unmark\n",
      "                        as outputs.\n",
      "  --trt-network-func-name TRT_NETWORK_FUNC_NAME\n",
      "                        When using a trt-network-script instead of other model\n",
      "                        types, this specifies the name of the function that\n",
      "                        loads the network. Defaults to `load_network`.\n",
      "\n",
      "TensorRT Engine Save Options:\n",
      "  Options for saving TensorRT engines\n",
      "\n",
      "  --save-engine SAVE_ENGINE, --save-engine SAVE_ENGINE\n",
      "                        Path to save the TensorRT Engine\n",
      "\n",
      "TensorRT Legacy:\n",
      "  [DEPRECATED] Options for TensorRT Legacy. Reuses TensorRT options, but\n",
      "  does not support int8 mode, or dynamic shapes\n",
      "\n",
      "  -p PREPROCESSOR, --preprocessor PREPROCESSOR\n",
      "                        The preprocessor to use for the UFF converter\n",
      "  --uff-order UFF_ORDER\n",
      "                        The order of the input\n",
      "  --batch-size SIZE     The batch size to use in TensorRT when it cannot be\n",
      "                        automatically determined\n",
      "  --model CAFFE_MODEL   Model file for Caffe models. The deploy file should be\n",
      "                        provided as the model_file positional argument\n",
      "  --save-uff            Save intermediate UFF files\n",
      "\n",
      "Data Loader:\n",
      "  Options for controlling how input data is loaded or generated\n",
      "\n",
      "  --seed SEED           Seed to use for random inputs\n",
      "  --val-range VAL_RANGE [VAL_RANGE ...]\n",
      "                        Range of values to generate in the data loader. To\n",
      "                        specify per-input ranges, use the format: --val-range\n",
      "                        <out_name>:[min,max]. If no input name is provided,\n",
      "                        the range is used for any inputs not explicitly\n",
      "                        specified. For example: --val-range [0,1] inp0:[2,50]\n",
      "                        inp1:[3.0,4.6]\n",
      "  --int-min INT_MIN     [DEPRECATED: Use --val-range] Minimum integer value\n",
      "                        for random integer inputs\n",
      "  --int-max INT_MAX     [DEPRECATED: Use --val-range] Maximum integer value\n",
      "                        for random integer inputs\n",
      "  --float-min FLOAT_MIN\n",
      "                        [DEPRECATED: Use --val-range] Minimum float value for\n",
      "                        random float inputs\n",
      "  --float-max FLOAT_MAX\n",
      "                        [DEPRECATED: Use --val-range] Maximum float value for\n",
      "                        random float inputs\n",
      "  --iterations NUM, --iters NUM\n",
      "                        Number of inference iterations for which to supply\n",
      "                        data\n",
      "  --load-inputs LOAD_INPUTS [LOAD_INPUTS ...], --load-input-data LOAD_INPUTS [LOAD_INPUTS ...]\n",
      "                        [EXPERIMENTAL] Path(s) to load inputs. The file(s)\n",
      "                        should be a JSON-ified List[Dict[str, numpy.ndarray]],\n",
      "                        i.e. a list where each element is the feed_dict for a\n",
      "                        single iteration. Other data loader options are\n",
      "                        ignored when this option is used\n",
      "  --data-loader-script DATA_LOADER_SCRIPT\n",
      "                        Path to a Python script that defines a function that\n",
      "                        loads input data. The function should take no\n",
      "                        arguments and return a generator or iterable that\n",
      "                        yields input data (Dict[str, np.ndarray]). When this\n",
      "                        option is specified, all other data loader arguments\n",
      "                        are ignored.\n",
      "  --data-loader-func-name DATA_LOADER_FUNC_NAME\n",
      "                        When using a data-loader-script, this specifies the\n",
      "                        name of the function that loads data. Defaults to\n",
      "                        `load_data`.\n",
      "\n",
      "Comparator inference:\n",
      "  Options for running inference via Comparator.run()\n",
      "\n",
      "  --warm-up NUM         Number of warm-up runs before timing inference\n",
      "  --use-subprocess      Run runners in isolated subprocesses. Cannot be used\n",
      "                        with a debugger\n",
      "  --save-inputs SAVE_INPUTS, --save-input-data SAVE_INPUTS\n",
      "                        [EXPERIMENTAL] Path to save inference inputs. The\n",
      "                        inputs (List[Dict[str, numpy.ndarray]]) will be\n",
      "                        encoded as JSON and saved\n",
      "  --save-outputs SAVE_RESULTS, --save-results SAVE_RESULTS\n",
      "                        Path to save results from runners. The results\n",
      "                        (RunResults) will be encoded as JSON and saved\n",
      "\n",
      "Comparator comparisons:\n",
      "  Options for comparing inference results\n",
      "\n",
      "  --no-shape-check      Disable checking that output shapes match exactly\n",
      "  --rtol RTOL [RTOL ...], --rel-tol RTOL [RTOL ...]\n",
      "                        Relative tolerance for output comparison. To specify\n",
      "                        per-output tolerances, use the format: --rtol\n",
      "                        [<out_name>:]<rtol>. If no output name is provided,\n",
      "                        the tolerance is used for any outputs not explicitly\n",
      "                        specified. For example: --rtol 1e-5 out0:1e-4\n",
      "                        out1:1e-3\n",
      "  --atol ATOL [ATOL ...], --abs-tol ATOL [ATOL ...]\n",
      "                        Absolute tolerance for output comparison. To specify\n",
      "                        per-output tolerances, use the format: --atol\n",
      "                        [<out_name>:]<atol>. If no output name is provided,\n",
      "                        the tolerance is used for any outputs not explicitly\n",
      "                        specified. For example: --atol 1e-5 out0:1e-4\n",
      "                        out1:1e-3\n",
      "  --validate            Check outputs for NaNs and Infs\n",
      "  --fail-fast           Fail fast (stop comparing after the first failure)\n",
      "  --top-k TOP_K [TOP_K ...]\n",
      "                        [EXPERIMENTAL] Apply Top-K (i.e. find indices of K\n",
      "                        largest values) to the outputs before comparing\n",
      "                        them.To specify per-output top-k, use the format:\n",
      "                        --top-k [<out_name>:]<k>. If no output name is\n",
      "                        provided, top-k is applied to all outputs. For\n",
      "                        example: --top-k out:5\n",
      "  --check-error-stat CHECK_ERROR_STAT [CHECK_ERROR_STAT ...]\n",
      "                        The error statistic to check. For details on possible\n",
      "                        values, see the documentation for\n",
      "                        CompareFunc.simple(). To specify per-output values,\n",
      "                        use the format: --check-error-stat\n",
      "                        [<out_name>:]<stat>. If no output name is provided,\n",
      "                        the value is used for any outputs not explicitly\n",
      "                        specified. For example: --check-error-stat max\n",
      "                        out0:mean out1:median\n",
      "  --load-outputs LOAD_RESULTS [LOAD_RESULTS ...], --load-results LOAD_RESULTS [LOAD_RESULTS ...]\n",
      "                        Path(s) to load results from runners prior to\n",
      "                        comparing. Each file should be a JSON-ified RunResults\n",
      "\n",
      "Runners:\n",
      "  Options for selecting runners. Zero or more runners may be specified\n",
      "\n",
      "  --trt                 Run inference using TensorRT\n",
      "  --trt-legacy          Run inference using Legacy TensorRT Runner. Only\n",
      "                        supports networks using implicit batch mode\n",
      "  --tf                  Run inference using TensorFlow\n",
      "  --onnxrt              Run inference using ONNX Runtime\n",
      "  --pluginref           Run inference for models containing single TensorRT\n",
      "                        plugins using a CPU reference implementation\n"
     ]
    }
   ],
   "source": [
    "!polygraphy run -h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run 的参数一大片, 还是要仔细读一下.\n",
    "\n",
    "主要的功能已经一句话讲完了, `Run inference and compare results across backends.`, 用来运行推理, 并比较不同后端的结果的.\n",
    "这部分功能可以用来调试模型转换."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;14m[I] onnxrt-runner-N0-01/17/23-14:21:50  | Activating and starting inference\u001b[0m\n",
      "[I] Loading model: /workspace/examples/onnx/model_torch.onnx\n",
      "[I] onnxrt-runner-N0-01/17/23-14:21:50 \n",
      "    ---- Inference Input(s) ----\n",
      "    {input_ids [dtype=int64, shape=(1, 128)],\n",
      "     attention_mask [dtype=int64, shape=(1, 128)],\n",
      "     token_type_ids [dtype=int64, shape=(1, 128)]}\n",
      "[I] onnxrt-runner-N0-01/17/23-14:21:50 \n",
      "    ---- Inference Output(s) ----\n",
      "    {/bert/Unsqueeze_output_0 [dtype=int64, shape=(1, 1, 128)],\n",
      "     /bert/Unsqueeze_1_output_0 [dtype=int64, shape=(1, 1, 1, 128)],\n",
      "     /bert/Cast_output_0 [dtype=float32, shape=(1, 1, 1, 128)],\n",
      "     /bert/Sub_output_0 [dtype=float32, shape=(1, 1, 1, 128)],\n",
      "     /bert/Mul_output_0 [dtype=float32, shape=(1, 1, 1, 128)],\n",
      "     /bert/embeddings/Shape_output_0 [dtype=int64, shape=(2,)],\n",
      "     /bert/embeddings/Gather_output_0 [dtype=int64, shape=()],\n",
      "     /bert/embeddings/Unsqueeze_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/embeddings/Slice_output_0 [dtype=int64, shape=(1, 128)],\n",
      "     /bert/embeddings/word_embeddings/Gather_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/embeddings/token_type_embeddings/Gather_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/embeddings/position_embeddings/Gather_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/embeddings/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/embeddings/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/embeddings/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/embeddings/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/embeddings/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/embeddings/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/embeddings/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/embeddings/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/embeddings/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/embeddings/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/embeddings/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/self/query/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/self/query/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/self/key/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/self/key/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/self/Shape_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.0/attention/self/Gather_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.0/attention/self/Shape_1_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.0/attention/self/Gather_1_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.0/attention/self/Unsqueeze_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.0/attention/self/Concat_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.0/attention/self/Reshape_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.0/attention/self/value/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/self/value/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/self/Shape_2_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.0/attention/self/Gather_2_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.0/attention/self/Shape_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.0/attention/self/Gather_3_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.0/attention/self/Concat_1_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.0/attention/self/Reshape_1_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.0/attention/self/Transpose_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.0/attention/self/Shape_4_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.0/attention/self/Gather_4_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.0/attention/self/Shape_5_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.0/attention/self/Gather_5_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.0/attention/self/Concat_2_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.0/attention/self/Reshape_2_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.0/attention/self/Transpose_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.0/attention/self/Transpose_2_output_0 [dtype=float32, shape=(1, 12, 64, 128)],\n",
      "     /bert/encoder/layer.0/attention/self/MatMul_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.0/attention/self/Div_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.0/attention/self/Add_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.0/attention/self/Softmax_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.0/attention/self/MatMul_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.0/attention/self/Transpose_3_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.0/attention/self/Shape_6_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.0/attention/self/Gather_6_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.0/attention/self/Shape_7_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.0/attention/self/Gather_7_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.0/attention/self/Concat_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.0/attention/self/Reshape_3_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/intermediate/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.0/intermediate/dense/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.0/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.0/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.0/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.0/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/self/query/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/self/query/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/self/key/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/self/key/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/self/Shape_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.1/attention/self/Gather_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.1/attention/self/Shape_1_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.1/attention/self/Gather_1_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.1/attention/self/Unsqueeze_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.1/attention/self/Concat_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.1/attention/self/Reshape_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.1/attention/self/value/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/self/value/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/self/Shape_2_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.1/attention/self/Gather_2_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.1/attention/self/Shape_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.1/attention/self/Gather_3_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.1/attention/self/Concat_1_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.1/attention/self/Reshape_1_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.1/attention/self/Transpose_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.1/attention/self/Shape_4_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.1/attention/self/Gather_4_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.1/attention/self/Shape_5_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.1/attention/self/Gather_5_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.1/attention/self/Concat_2_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.1/attention/self/Reshape_2_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.1/attention/self/Transpose_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.1/attention/self/Transpose_2_output_0 [dtype=float32, shape=(1, 12, 64, 128)],\n",
      "     /bert/encoder/layer.1/attention/self/MatMul_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.1/attention/self/Div_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.1/attention/self/Add_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.1/attention/self/Softmax_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.1/attention/self/MatMul_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.1/attention/self/Transpose_3_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.1/attention/self/Shape_6_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.1/attention/self/Gather_6_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.1/attention/self/Shape_7_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.1/attention/self/Gather_7_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.1/attention/self/Concat_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.1/attention/self/Reshape_3_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/intermediate/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.1/intermediate/dense/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.1/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.1/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.1/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.1/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/self/query/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/self/query/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/self/key/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/self/key/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/self/Shape_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.2/attention/self/Gather_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.2/attention/self/Shape_1_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.2/attention/self/Gather_1_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.2/attention/self/Unsqueeze_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.2/attention/self/Concat_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.2/attention/self/Reshape_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.2/attention/self/value/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/self/value/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/self/Shape_2_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.2/attention/self/Gather_2_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.2/attention/self/Shape_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.2/attention/self/Gather_3_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.2/attention/self/Concat_1_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.2/attention/self/Reshape_1_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.2/attention/self/Transpose_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.2/attention/self/Shape_4_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.2/attention/self/Gather_4_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.2/attention/self/Shape_5_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.2/attention/self/Gather_5_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.2/attention/self/Concat_2_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.2/attention/self/Reshape_2_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.2/attention/self/Transpose_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.2/attention/self/Transpose_2_output_0 [dtype=float32, shape=(1, 12, 64, 128)],\n",
      "     /bert/encoder/layer.2/attention/self/MatMul_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.2/attention/self/Div_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.2/attention/self/Add_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.2/attention/self/Softmax_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.2/attention/self/MatMul_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.2/attention/self/Transpose_3_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.2/attention/self/Shape_6_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.2/attention/self/Gather_6_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.2/attention/self/Shape_7_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.2/attention/self/Gather_7_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.2/attention/self/Concat_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.2/attention/self/Reshape_3_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/intermediate/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.2/intermediate/dense/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.2/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.2/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.2/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.2/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/self/query/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/self/query/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/self/key/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/self/key/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/self/Shape_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.3/attention/self/Gather_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.3/attention/self/Shape_1_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.3/attention/self/Gather_1_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.3/attention/self/Unsqueeze_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.3/attention/self/Concat_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.3/attention/self/Reshape_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.3/attention/self/value/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/self/value/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/self/Shape_2_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.3/attention/self/Gather_2_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.3/attention/self/Shape_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.3/attention/self/Gather_3_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.3/attention/self/Concat_1_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.3/attention/self/Reshape_1_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.3/attention/self/Transpose_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.3/attention/self/Shape_4_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.3/attention/self/Gather_4_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.3/attention/self/Shape_5_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.3/attention/self/Gather_5_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.3/attention/self/Concat_2_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.3/attention/self/Reshape_2_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.3/attention/self/Transpose_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.3/attention/self/Transpose_2_output_0 [dtype=float32, shape=(1, 12, 64, 128)],\n",
      "     /bert/encoder/layer.3/attention/self/MatMul_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.3/attention/self/Div_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.3/attention/self/Add_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.3/attention/self/Softmax_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.3/attention/self/MatMul_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.3/attention/self/Transpose_3_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.3/attention/self/Shape_6_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.3/attention/self/Gather_6_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.3/attention/self/Shape_7_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.3/attention/self/Gather_7_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.3/attention/self/Concat_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.3/attention/self/Reshape_3_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/intermediate/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.3/intermediate/dense/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.3/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.3/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.3/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.3/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/self/query/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/self/query/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/self/key/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/self/key/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/self/Shape_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.4/attention/self/Gather_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.4/attention/self/Shape_1_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.4/attention/self/Gather_1_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.4/attention/self/Unsqueeze_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.4/attention/self/Concat_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.4/attention/self/Reshape_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.4/attention/self/value/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/self/value/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/self/Shape_2_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.4/attention/self/Gather_2_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.4/attention/self/Shape_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.4/attention/self/Gather_3_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.4/attention/self/Concat_1_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.4/attention/self/Reshape_1_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.4/attention/self/Transpose_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.4/attention/self/Shape_4_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.4/attention/self/Gather_4_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.4/attention/self/Shape_5_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.4/attention/self/Gather_5_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.4/attention/self/Concat_2_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.4/attention/self/Reshape_2_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.4/attention/self/Transpose_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.4/attention/self/Transpose_2_output_0 [dtype=float32, shape=(1, 12, 64, 128)],\n",
      "     /bert/encoder/layer.4/attention/self/MatMul_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.4/attention/self/Div_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.4/attention/self/Add_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.4/attention/self/Softmax_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.4/attention/self/MatMul_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.4/attention/self/Transpose_3_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.4/attention/self/Shape_6_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.4/attention/self/Gather_6_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.4/attention/self/Shape_7_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.4/attention/self/Gather_7_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.4/attention/self/Concat_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.4/attention/self/Reshape_3_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/intermediate/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.4/intermediate/dense/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.4/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.4/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.4/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.4/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/self/query/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/self/query/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/self/key/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/self/key/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/self/Shape_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.5/attention/self/Gather_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.5/attention/self/Shape_1_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.5/attention/self/Gather_1_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.5/attention/self/Unsqueeze_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.5/attention/self/Concat_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.5/attention/self/Reshape_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.5/attention/self/value/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/self/value/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/self/Shape_2_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.5/attention/self/Gather_2_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.5/attention/self/Shape_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.5/attention/self/Gather_3_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.5/attention/self/Concat_1_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.5/attention/self/Reshape_1_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.5/attention/self/Transpose_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.5/attention/self/Shape_4_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.5/attention/self/Gather_4_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.5/attention/self/Shape_5_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.5/attention/self/Gather_5_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.5/attention/self/Concat_2_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.5/attention/self/Reshape_2_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.5/attention/self/Transpose_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.5/attention/self/Transpose_2_output_0 [dtype=float32, shape=(1, 12, 64, 128)],\n",
      "     /bert/encoder/layer.5/attention/self/MatMul_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.5/attention/self/Div_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.5/attention/self/Add_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.5/attention/self/Softmax_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.5/attention/self/MatMul_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.5/attention/self/Transpose_3_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.5/attention/self/Shape_6_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.5/attention/self/Gather_6_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.5/attention/self/Shape_7_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.5/attention/self/Gather_7_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.5/attention/self/Concat_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.5/attention/self/Reshape_3_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/intermediate/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.5/intermediate/dense/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.5/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.5/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.5/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.5/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.5/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/self/query/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/self/query/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/self/key/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/self/key/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/self/Shape_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.6/attention/self/Gather_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.6/attention/self/Shape_1_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.6/attention/self/Gather_1_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.6/attention/self/Unsqueeze_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.6/attention/self/Unsqueeze_1_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.6/attention/self/Concat_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.6/attention/self/Reshape_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.6/attention/self/value/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/self/value/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/self/Shape_2_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.6/attention/self/Gather_2_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.6/attention/self/Shape_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.6/attention/self/Gather_3_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.6/attention/self/Unsqueeze_2_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.6/attention/self/Unsqueeze_3_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.6/attention/self/Concat_1_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.6/attention/self/Reshape_1_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.6/attention/self/Transpose_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.6/attention/self/Shape_4_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.6/attention/self/Gather_4_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.6/attention/self/Shape_5_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.6/attention/self/Gather_5_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.6/attention/self/Unsqueeze_4_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.6/attention/self/Unsqueeze_5_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.6/attention/self/Concat_2_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.6/attention/self/Reshape_2_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.6/attention/self/Transpose_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.6/attention/self/Transpose_2_output_0 [dtype=float32, shape=(1, 12, 64, 128)],\n",
      "     /bert/encoder/layer.6/attention/self/MatMul_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.6/attention/self/Div_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.6/attention/self/Add_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.6/attention/self/Softmax_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.6/attention/self/MatMul_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.6/attention/self/Transpose_3_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.6/attention/self/Shape_6_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.6/attention/self/Gather_6_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.6/attention/self/Shape_7_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.6/attention/self/Gather_7_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.6/attention/self/Unsqueeze_6_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.6/attention/self/Unsqueeze_7_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.6/attention/self/Concat_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.6/attention/self/Reshape_3_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.6/attention/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.6/attention/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.6/attention/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.6/attention/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/intermediate/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.6/intermediate/dense/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.6/intermediate/intermediate_act_fn/Div_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.6/intermediate/intermediate_act_fn/Erf_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.6/intermediate/intermediate_act_fn/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.6/intermediate/intermediate_act_fn/Mul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.6/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.6/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.6/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.6/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.6/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.6/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/self/query/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/self/query/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/self/key/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/self/key/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/self/Shape_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.7/attention/self/Gather_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.7/attention/self/Shape_1_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.7/attention/self/Gather_1_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.7/attention/self/Unsqueeze_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.7/attention/self/Unsqueeze_1_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.7/attention/self/Concat_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.7/attention/self/Reshape_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.7/attention/self/value/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/self/value/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/self/Shape_2_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.7/attention/self/Gather_2_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.7/attention/self/Shape_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.7/attention/self/Gather_3_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.7/attention/self/Unsqueeze_2_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.7/attention/self/Unsqueeze_3_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.7/attention/self/Concat_1_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.7/attention/self/Reshape_1_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.7/attention/self/Transpose_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.7/attention/self/Shape_4_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.7/attention/self/Gather_4_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.7/attention/self/Shape_5_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.7/attention/self/Gather_5_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.7/attention/self/Unsqueeze_4_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.7/attention/self/Unsqueeze_5_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.7/attention/self/Concat_2_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.7/attention/self/Reshape_2_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.7/attention/self/Transpose_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.7/attention/self/Transpose_2_output_0 [dtype=float32, shape=(1, 12, 64, 128)],\n",
      "     /bert/encoder/layer.7/attention/self/MatMul_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.7/attention/self/Div_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.7/attention/self/Add_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.7/attention/self/Softmax_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.7/attention/self/MatMul_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.7/attention/self/Transpose_3_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.7/attention/self/Shape_6_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.7/attention/self/Gather_6_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.7/attention/self/Shape_7_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.7/attention/self/Gather_7_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.7/attention/self/Unsqueeze_6_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.7/attention/self/Unsqueeze_7_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.7/attention/self/Concat_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.7/attention/self/Reshape_3_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.7/attention/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.7/attention/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.7/attention/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.7/attention/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/intermediate/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.7/intermediate/dense/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.7/intermediate/intermediate_act_fn/Div_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.7/intermediate/intermediate_act_fn/Erf_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.7/intermediate/intermediate_act_fn/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.7/intermediate/intermediate_act_fn/Mul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.7/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.7/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.7/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.7/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.7/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.7/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/self/query/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/self/query/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/self/key/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/self/key/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/self/Shape_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.8/attention/self/Gather_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.8/attention/self/Shape_1_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.8/attention/self/Gather_1_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.8/attention/self/Unsqueeze_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.8/attention/self/Unsqueeze_1_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.8/attention/self/Concat_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.8/attention/self/Reshape_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.8/attention/self/value/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/self/value/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/self/Shape_2_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.8/attention/self/Gather_2_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.8/attention/self/Shape_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.8/attention/self/Gather_3_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.8/attention/self/Unsqueeze_2_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.8/attention/self/Unsqueeze_3_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.8/attention/self/Concat_1_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.8/attention/self/Reshape_1_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.8/attention/self/Transpose_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.8/attention/self/Shape_4_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.8/attention/self/Gather_4_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.8/attention/self/Shape_5_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.8/attention/self/Gather_5_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.8/attention/self/Unsqueeze_4_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.8/attention/self/Unsqueeze_5_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.8/attention/self/Concat_2_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.8/attention/self/Reshape_2_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.8/attention/self/Transpose_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.8/attention/self/Transpose_2_output_0 [dtype=float32, shape=(1, 12, 64, 128)],\n",
      "     /bert/encoder/layer.8/attention/self/MatMul_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.8/attention/self/Div_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.8/attention/self/Add_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.8/attention/self/Softmax_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.8/attention/self/MatMul_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.8/attention/self/Transpose_3_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.8/attention/self/Shape_6_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.8/attention/self/Gather_6_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.8/attention/self/Shape_7_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.8/attention/self/Gather_7_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.8/attention/self/Unsqueeze_6_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.8/attention/self/Unsqueeze_7_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.8/attention/self/Concat_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.8/attention/self/Reshape_3_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.8/attention/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.8/attention/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.8/attention/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.8/attention/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/intermediate/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.8/intermediate/dense/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.8/intermediate/intermediate_act_fn/Div_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.8/intermediate/intermediate_act_fn/Erf_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.8/intermediate/intermediate_act_fn/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.8/intermediate/intermediate_act_fn/Mul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.8/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.8/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.8/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.8/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.8/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.8/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/self/query/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/self/query/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/self/key/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/self/key/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/self/Shape_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.9/attention/self/Gather_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.9/attention/self/Shape_1_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.9/attention/self/Gather_1_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.9/attention/self/Unsqueeze_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.9/attention/self/Unsqueeze_1_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.9/attention/self/Concat_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.9/attention/self/Reshape_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.9/attention/self/value/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/self/value/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/self/Shape_2_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.9/attention/self/Gather_2_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.9/attention/self/Shape_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.9/attention/self/Gather_3_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.9/attention/self/Unsqueeze_2_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.9/attention/self/Unsqueeze_3_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.9/attention/self/Concat_1_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.9/attention/self/Reshape_1_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.9/attention/self/Transpose_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.9/attention/self/Shape_4_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.9/attention/self/Gather_4_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.9/attention/self/Shape_5_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.9/attention/self/Gather_5_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.9/attention/self/Unsqueeze_4_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.9/attention/self/Unsqueeze_5_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.9/attention/self/Concat_2_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.9/attention/self/Reshape_2_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.9/attention/self/Transpose_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.9/attention/self/Transpose_2_output_0 [dtype=float32, shape=(1, 12, 64, 128)],\n",
      "     /bert/encoder/layer.9/attention/self/MatMul_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.9/attention/self/Div_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.9/attention/self/Add_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.9/attention/self/Softmax_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.9/attention/self/MatMul_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.9/attention/self/Transpose_3_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.9/attention/self/Shape_6_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.9/attention/self/Gather_6_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.9/attention/self/Shape_7_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.9/attention/self/Gather_7_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.9/attention/self/Unsqueeze_6_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.9/attention/self/Unsqueeze_7_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.9/attention/self/Concat_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.9/attention/self/Reshape_3_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.9/attention/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.9/attention/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.9/attention/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.9/attention/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/intermediate/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.9/intermediate/dense/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.9/intermediate/intermediate_act_fn/Div_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.9/intermediate/intermediate_act_fn/Erf_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.9/intermediate/intermediate_act_fn/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.9/intermediate/intermediate_act_fn/Mul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.9/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.9/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.9/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.9/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.9/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.9/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/self/query/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/self/query/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/self/key/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/self/key/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/self/Shape_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.10/attention/self/Gather_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.10/attention/self/Shape_1_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.10/attention/self/Gather_1_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.10/attention/self/Unsqueeze_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.10/attention/self/Unsqueeze_1_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.10/attention/self/Concat_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.10/attention/self/Reshape_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.10/attention/self/value/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/self/value/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/self/Shape_2_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.10/attention/self/Gather_2_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.10/attention/self/Shape_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.10/attention/self/Gather_3_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.10/attention/self/Unsqueeze_2_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.10/attention/self/Unsqueeze_3_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.10/attention/self/Concat_1_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.10/attention/self/Reshape_1_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.10/attention/self/Transpose_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.10/attention/self/Shape_4_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.10/attention/self/Gather_4_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.10/attention/self/Shape_5_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.10/attention/self/Gather_5_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.10/attention/self/Unsqueeze_4_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.10/attention/self/Unsqueeze_5_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.10/attention/self/Concat_2_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.10/attention/self/Reshape_2_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.10/attention/self/Transpose_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.10/attention/self/Transpose_2_output_0 [dtype=float32, shape=(1, 12, 64, 128)],\n",
      "     /bert/encoder/layer.10/attention/self/MatMul_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.10/attention/self/Div_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.10/attention/self/Add_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.10/attention/self/Softmax_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.10/attention/self/MatMul_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.10/attention/self/Transpose_3_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.10/attention/self/Shape_6_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.10/attention/self/Gather_6_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.10/attention/self/Shape_7_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.10/attention/self/Gather_7_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.10/attention/self/Unsqueeze_6_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.10/attention/self/Unsqueeze_7_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.10/attention/self/Concat_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.10/attention/self/Reshape_3_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.10/attention/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.10/attention/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.10/attention/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.10/attention/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/intermediate/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.10/intermediate/dense/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.10/intermediate/intermediate_act_fn/Div_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.10/intermediate/intermediate_act_fn/Erf_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.10/intermediate/intermediate_act_fn/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.10/intermediate/intermediate_act_fn/Mul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.10/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.10/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.10/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.10/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.10/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.10/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/self/query/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/self/query/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/self/key/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/self/key/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/self/Shape_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.11/attention/self/Gather_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.11/attention/self/Shape_1_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.11/attention/self/Gather_1_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.11/attention/self/Unsqueeze_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.11/attention/self/Unsqueeze_1_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.11/attention/self/Concat_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.11/attention/self/Reshape_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.11/attention/self/value/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/self/value/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/self/Shape_2_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.11/attention/self/Gather_2_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.11/attention/self/Shape_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.11/attention/self/Gather_3_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.11/attention/self/Unsqueeze_2_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.11/attention/self/Unsqueeze_3_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.11/attention/self/Concat_1_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.11/attention/self/Reshape_1_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.11/attention/self/Transpose_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.11/attention/self/Shape_4_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.11/attention/self/Gather_4_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.11/attention/self/Shape_5_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.11/attention/self/Gather_5_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.11/attention/self/Unsqueeze_4_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.11/attention/self/Unsqueeze_5_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.11/attention/self/Concat_2_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.11/attention/self/Reshape_2_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.11/attention/self/Transpose_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.11/attention/self/Transpose_2_output_0 [dtype=float32, shape=(1, 12, 64, 128)],\n",
      "     /bert/encoder/layer.11/attention/self/MatMul_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.11/attention/self/Div_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.11/attention/self/Add_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.11/attention/self/Softmax_output_0 [dtype=float32, shape=(1, 12, 128, 128)],\n",
      "     /bert/encoder/layer.11/attention/self/MatMul_1_output_0 [dtype=float32, shape=(1, 12, 128, 64)],\n",
      "     /bert/encoder/layer.11/attention/self/Transpose_3_output_0 [dtype=float32, shape=(1, 128, 12, 64)],\n",
      "     /bert/encoder/layer.11/attention/self/Shape_6_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.11/attention/self/Gather_6_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.11/attention/self/Shape_7_output_0 [dtype=int64, shape=(4,)],\n",
      "     /bert/encoder/layer.11/attention/self/Gather_7_output_0 [dtype=int64, shape=()],\n",
      "     /bert/encoder/layer.11/attention/self/Unsqueeze_6_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.11/attention/self/Unsqueeze_7_output_0 [dtype=int64, shape=(1,)],\n",
      "     /bert/encoder/layer.11/attention/self/Concat_3_output_0 [dtype=int64, shape=(3,)],\n",
      "     /bert/encoder/layer.11/attention/self/Reshape_3_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.11/attention/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.11/attention/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.11/attention/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.11/attention/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/intermediate/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.11/intermediate/dense/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.11/intermediate/intermediate_act_fn/Div_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.11/intermediate/intermediate_act_fn/Erf_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.11/intermediate/intermediate_act_fn/Add_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.11/intermediate/intermediate_act_fn/Mul_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0 [dtype=float32, shape=(1, 128, 3072)],\n",
      "     /bert/encoder/layer.11/output/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/output/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/output/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/output/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.11/output/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/output/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/output/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.11/output/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.11/output/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /bert/encoder/layer.11/output/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/output/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /bert/encoder/layer.11/output/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /cls/predictions/transform/dense/MatMul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /cls/predictions/transform/dense/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /cls/predictions/transform/transform_act_fn/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /cls/predictions/transform/transform_act_fn/Erf_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /cls/predictions/transform/transform_act_fn/Add_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /cls/predictions/transform/transform_act_fn/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /cls/predictions/transform/transform_act_fn/Mul_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /cls/predictions/transform/LayerNorm/ReduceMean_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /cls/predictions/transform/LayerNorm/Sub_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /cls/predictions/transform/LayerNorm/Pow_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /cls/predictions/transform/LayerNorm/ReduceMean_1_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /cls/predictions/transform/LayerNorm/Add_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /cls/predictions/transform/LayerNorm/Sqrt_output_0 [dtype=float32, shape=(1, 128, 1)],\n",
      "     /cls/predictions/transform/LayerNorm/Div_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /cls/predictions/transform/LayerNorm/Mul_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /cls/predictions/transform/LayerNorm/Add_1_output_0 [dtype=float32, shape=(1, 128, 768)],\n",
      "     /cls/predictions/decoder/MatMul_output_0 [dtype=float32, shape=(1, 128, 30522)],\n",
      "     logits [dtype=float32, shape=(1, 128, 30522)]}\n",
      "\u001b[38;5;10m[I] onnxrt-runner-N0-01/17/23-14:21:50  | Completed 1 iteration(s) in 169.2 ms | Average inference time: 169.2 ms.\u001b[0m\n",
      "[I] Saving inference results to onnx_out.pkl\n",
      "\u001b[38;5;10m[I] PASSED | Command: /opt/conda/bin/polygraphy run ./onnx/model_torch.onnx --onnxrt --onnx-outputs mark all --save-results=onnx_out.pkl --data-loader-script /workspace/examples/data_loader.py\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 手动修复下 /opt/conda/lib/python3.8/site-packages/polygraphy/backend/onnxrt/loader.py 中的最后一行, 提供下 providers\n",
    "# return onnxruntime.InferenceSession(model_bytes, providers=[\"CUDAExecutionProvider\"])\n",
    "!polygraphy run ./onnx/model_torch.onnx --onnxrt --onnx-outputs mark all --save-results=onnx_out.json \\\n",
    "    --data-loader-script /workspace/examples/data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;14m[I] trt-runner-N0-01/17/23-14:44:05     | Activating and starting inference\u001b[0m\n",
      "[01/17/2023-14:44:06] [TRT] [W] parsers/onnx/onnx2trt_utils.cpp:368: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[01/17/2023-14:44:08] [TRT] [W] Output type must be INT32 for shape outputs\n",
      "[01/17/2023-14:44:08] [TRT] [W] Output type must be INT32 for shape outputs\n",
      "[01/17/2023-14:44:08] [TRT] [W] Output type must be INT32 for shape outputs\n",
      "[01/17/2023-14:44:08] [TRT] [W] Output type must be INT32 for shape outputs\n",
      "[I]     Configuring with profiles: [Profile().add(input_ids, min=[1, 128], opt=[1, 128], max=[1, 128]).add(attention_mask, min=[1, 128], opt=[1, 128], max=[1, 128]).add(token_type_ids, min=[1, 128], opt=[1, 128], max=[1, 128])]\n",
      "\u001b[38;5;14m[I] Building engine with configuration:\n",
      "    Workspace            | 16777216 bytes (16.00 MiB)\n",
      "    Precision            | TF32: False, FP16: False, INT8: False, Strict Types: False\n",
      "    Tactic Sources       | ['CUBLAS', 'CUBLAS_LT', 'CUDNN']\n",
      "    Safety Restricted    | False\n",
      "    Profiles             | 1 profile(s)\u001b[0m\n",
      "terminate called after throwing an instance of 'nvinfer1::InternalError'\n",
      "  what():  [HostToDeviceCopy]requires bool I/O but node can not be handled by Myelin.\n"
     ]
    }
   ],
   "source": [
    "!polygraphy run ./onnx/model_torch.onnx --trt --validate --trt-outputs mark all --save-results=trt_out.json \\\n",
    "    --data-loader-script /workspace/examples/data_loader.py \\\n",
    "    --trt-min-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128] \\\n",
    "    --trt-opt-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128] \\\n",
    "    --trt-max-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: polygraphy debug [-h] [-v] [-q] [--silent]\n",
      "                        [--log-format {timestamp,line-info,no-colors} [{timestamp,line-info,no-colors} ...]]\n",
      "                        [--log-file LOG_FILE]\n",
      "                        {build,precision,diff-tactics,reduce,repeat} ...\n",
      "\n",
      "[EXPERIMENTAL] Debug model accuracy issues.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "Logging:\n",
      "  Options for logging and debug output\n",
      "\n",
      "  -v, --verbose         Increase logging verbosity. Specify multiple times for\n",
      "                        higher verbosity\n",
      "  -q, --quiet           Decrease logging verbosity. Specify multiple times for\n",
      "                        lower verbosity\n",
      "  --silent              Disable all output\n",
      "  --log-format {timestamp,line-info,no-colors} [{timestamp,line-info,no-colors} ...]\n",
      "                        Format for log messages: {{'timestamp': Include\n",
      "                        timestamp, 'line-info': Include file and line number,\n",
      "                        'no-colors': Disable colors}}\n",
      "  --log-file LOG_FILE   Path to a file where Polygraphy logging output should\n",
      "                        be written. This will not include logging output from\n",
      "                        dependencies, like TensorRT or ONNX-Runtime.\n",
      "\n",
      "Debug Subtools:\n",
      "  {build,precision,diff-tactics,reduce,repeat}\n",
      "    build               Repeatedly build an engine to isolate flaky behavior,\n",
      "                        sorting generated artifacts into `good` and `bad`\n",
      "                        directories. Each iteration will generate an engine\n",
      "                        called 'polygraphy_debug.engine' in the current\n",
      "                        directory.\n",
      "    precision           Iteratively mark layers to run in a higher precision\n",
      "                        to find a compromise between performance and quality.\n",
      "                        Each iteration will generate an engine called\n",
      "                        'polygraphy_debug.engine' in the current directory.\n",
      "    diff-tactics        Determine potentially bad tactics given sets of good\n",
      "                        and bad tactic replay files.\n",
      "    reduce              [EXPERIMENTAL] Reduce a failing ONNX model to the\n",
      "                        minimum set of nodes that cause the failure. Each\n",
      "                        iteration will generate an ONNX model called\n",
      "                        'polygraphy_debug.onnx' in the current directory.\n",
      "    repeat              [EXPERIMENTAL] Run an arbitrary command repeatedly,\n",
      "                        sorting generated artifacts into `good` and `bad`\n",
      "                        directories.\n"
     ]
    }
   ],
   "source": [
    "!polygraphy debug --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: polygraphy debug precision [-h] [-v] [-q] [--silent]\n",
      "                                  [--log-format {timestamp,line-info,no-colors} [{timestamp,line-info,no-colors} ...]]\n",
      "                                  [--log-file LOG_FILE]\n",
      "                                  [--artifacts ARTIFACTS [ARTIFACTS ...]]\n",
      "                                  [--art-dir DIR] --check ...\n",
      "                                  [--fail-code FAIL_CODES [FAIL_CODES ...] |\n",
      "                                  --ignore-fail-code IGNORE_FAIL_CODES\n",
      "                                  [IGNORE_FAIL_CODES ...]]\n",
      "                                  [--fail-regex FAIL_REGEX [FAIL_REGEX ...]]\n",
      "                                  [--show-output | --hide-fail-output]\n",
      "                                  [--iter-artifact ITER_ARTIFACT]\n",
      "                                  [--no-remove-intermediate]\n",
      "                                  [--iter-info ITERATION_INFO]\n",
      "                                  [--model-type {frozen,keras,ckpt,onnx,engine,uff,trt-network-script,caffe}]\n",
      "                                  [--shape-inference]\n",
      "                                  [--external-data-dir LOAD_EXTERNAL_DATA]\n",
      "                                  [--seed SEED]\n",
      "                                  [--val-range VAL_RANGE [VAL_RANGE ...]]\n",
      "                                  [--int-min INT_MIN] [--int-max INT_MAX]\n",
      "                                  [--float-min FLOAT_MIN]\n",
      "                                  [--float-max FLOAT_MAX] [--iterations NUM]\n",
      "                                  [--load-inputs LOAD_INPUTS [LOAD_INPUTS ...]]\n",
      "                                  [--data-loader-script DATA_LOADER_SCRIPT]\n",
      "                                  [--data-loader-func-name DATA_LOADER_FUNC_NAME]\n",
      "                                  [--trt-min-shapes TRT_MIN_SHAPES [TRT_MIN_SHAPES ...]]\n",
      "                                  [--trt-opt-shapes TRT_OPT_SHAPES [TRT_OPT_SHAPES ...]]\n",
      "                                  [--trt-max-shapes TRT_MAX_SHAPES [TRT_MAX_SHAPES ...]]\n",
      "                                  [--tf32] [--fp16] [--int8]\n",
      "                                  [--no-strict-types] [--sparse-weights]\n",
      "                                  [--workspace BYTES]\n",
      "                                  [--calibration-cache CALIBRATION_CACHE]\n",
      "                                  [--calib-base-cls CALIBRATION_BASE_CLASS]\n",
      "                                  [--quantile QUANTILE]\n",
      "                                  [--regression-cutoff REGRESSION_CUTOFF]\n",
      "                                  [--timing-cache TIMING_CACHE]\n",
      "                                  [--tactic-replay TACTIC_REPLAY | --save-tactics SAVE_TACTICS | --load-tactics LOAD_TACTICS]\n",
      "                                  [--tactic-sources [TACTIC_SOURCES [TACTIC_SOURCES ...]]]\n",
      "                                  [--trt-config-script TRT_CONFIG_SCRIPT]\n",
      "                                  [--trt-config-func-name TRT_CONFIG_FUNC_NAME]\n",
      "                                  [--trt-safety-restricted] [--use-dla]\n",
      "                                  [--allow-gpu-fallback]\n",
      "                                  [--plugins PLUGINS [PLUGINS ...]]\n",
      "                                  [--explicit-precision]\n",
      "                                  [--trt-outputs TRT_OUTPUTS [TRT_OUTPUTS ...]]\n",
      "                                  [--trt-exclude-outputs TRT_EXCLUDE_OUTPUTS [TRT_EXCLUDE_OUTPUTS ...]]\n",
      "                                  [--trt-network-func-name TRT_NETWORK_FUNC_NAME]\n",
      "                                  [--mode {bisect,linear}]\n",
      "                                  [--dir {forward,reverse}] [-p {fp32,fp16}]\n",
      "                                  model_file\n",
      "\n",
      "Iteratively mark layers to run in a higher precision to find a compromise\n",
      "between performance and quality. Each iteration will generate an engine called\n",
      "'polygraphy_debug.engine' in the current directory.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --mode {bisect,linear}\n",
      "                        How layers are selected to run in higher precision.\n",
      "                        'bisect' will use binary search, and 'linear' will\n",
      "                        iteratively mark one extra layer at a time\n",
      "  --dir {forward,reverse}, --direction {forward,reverse}\n",
      "                        Order in which layers are marked to run in higher\n",
      "                        precision. 'forward' will start marking layers from\n",
      "                        network inputs, and 'reverse' will start from the\n",
      "                        network outputs\n",
      "  -p {fp32,fp16}, --precision {fp32,fp16}\n",
      "                        Precision to use when marking layers to run in higher\n",
      "                        precision\n",
      "\n",
      "Logging:\n",
      "  Options for logging and debug output\n",
      "\n",
      "  -v, --verbose         Increase logging verbosity. Specify multiple times for\n",
      "                        higher verbosity\n",
      "  -q, --quiet           Decrease logging verbosity. Specify multiple times for\n",
      "                        lower verbosity\n",
      "  --silent              Disable all output\n",
      "  --log-format {timestamp,line-info,no-colors} [{timestamp,line-info,no-colors} ...]\n",
      "                        Format for log messages: {{'timestamp': Include\n",
      "                        timestamp, 'line-info': Include file and line number,\n",
      "                        'no-colors': Disable colors}}\n",
      "  --log-file LOG_FILE   Path to a file where Polygraphy logging output should\n",
      "                        be written. This will not include logging output from\n",
      "                        dependencies, like TensorRT or ONNX-Runtime.\n",
      "\n",
      "Artifact Sorting:\n",
      "  Options for sorting artifacts\n",
      "\n",
      "  --artifacts ARTIFACTS [ARTIFACTS ...]\n",
      "                        Path(s) of artifacts to sort. These will be moved into\n",
      "                        'good' and 'bad' directories based on the exit status\n",
      "                        of the `--check` command and suffixed with an\n",
      "                        iteration number, timestamp and return code.\n",
      "  --art-dir DIR, --artifacts-dir DIR\n",
      "                        The directory in which to move artifacts and sort them\n",
      "                        into 'good' and 'bad'.\n",
      "  --check ..., --check-inference ...\n",
      "                        A command to check the model. The command should\n",
      "                        return an exit status of 0 for the run to be\n",
      "                        considered 'good'. Non-zero exit statuses are treated\n",
      "                        as 'bad' runs.\n",
      "  --fail-code FAIL_CODES [FAIL_CODES ...], --fail-returncode FAIL_CODES [FAIL_CODES ...]\n",
      "                        The return code(s) from the --check command to count\n",
      "                        as failures. If this is provided, any other return\n",
      "                        code will be counted as a success.\n",
      "  --ignore-fail-code IGNORE_FAIL_CODES [IGNORE_FAIL_CODES ...], --ignore-fail-returncode IGNORE_FAIL_CODES [IGNORE_FAIL_CODES ...]\n",
      "                        The return code(s) from the --check command to ignore\n",
      "                        as failures.\n",
      "  --fail-regex FAIL_REGEX [FAIL_REGEX ...]\n",
      "                        Regular expression denoting an error in the check\n",
      "                        command's output. The command is only considered a\n",
      "                        failure if a matching string is found in the command's\n",
      "                        output. This can be useful to distinguish among\n",
      "                        multiple types of failures. Can be specified multiple\n",
      "                        times to match different regular expressions, in which\n",
      "                        case any match counts as a failure. When combined with\n",
      "                        --fail-code, only iterations whose return code is\n",
      "                        considered a failure are checked for regular\n",
      "                        expressions.\n",
      "  --show-output         Show output from the --check command even for passing\n",
      "                        iterations. By default, output from passing iterations\n",
      "                        is captured.\n",
      "  --hide-fail-output    Suppress output from the --check command for failing\n",
      "                        iterations. By default, output from failing iterations\n",
      "                        is displayed.\n",
      "  --iter-artifact ITER_ARTIFACT, --intermediate-artifact ITER_ARTIFACT\n",
      "                        Path to store the intermediate artifact from each\n",
      "                        iteration. Defaults to: polygraphy_debug.engine\n",
      "  --no-remove-intermediate\n",
      "                        Do not remove the intermediate artifact between\n",
      "                        iterations. This allows you to exit the tool early and\n",
      "                        still have access to the intermediate artifact.\n",
      "  --iter-info ITERATION_INFO, --iteration-info ITERATION_INFO\n",
      "                        Path to write a JSON file containing information about\n",
      "                        the current iteration. This will include an\n",
      "                        'iteration' key specifying the current iteration.\n",
      "\n",
      "Model:\n",
      "  Options for the model\n",
      "\n",
      "  model_file            Path to the model\n",
      "  --model-type {frozen,keras,ckpt,onnx,engine,uff,trt-network-script,caffe}\n",
      "                        The type of the input model: {{'frozen': TensorFlow\n",
      "                        frozen graph, 'keras': Keras model, 'ckpt': TensorFlow\n",
      "                        checkpoint directory, 'onnx': ONNX model, 'engine':\n",
      "                        TensorRT engine, 'trt-network-script': A Python script\n",
      "                        that defines a `load_network` function that takes no\n",
      "                        arguments and returns a TensorRT Builder, Network, and\n",
      "                        optionally Parser, 'uff': UFF file [deprecated],\n",
      "                        'caffe': Caffe prototxt [deprecated]}}\n",
      "\n",
      "ONNX Shape Inference:\n",
      "  Options for ONNX Shape Inference\n",
      "\n",
      "  --shape-inference     Enable ONNX shape inference when loading the model\n",
      "\n",
      "ONNX Loader:\n",
      "  Options for the ONNX Loader\n",
      "\n",
      "  --external-data-dir LOAD_EXTERNAL_DATA, --load-external-data LOAD_EXTERNAL_DATA, --ext LOAD_EXTERNAL_DATA\n",
      "                        Path to a directory containing external data for the\n",
      "                        model. Generally, this is only required if the\n",
      "                        external data is not stored in the model directory.\n",
      "\n",
      "Data Loader:\n",
      "  Options for controlling how input data is loaded or generated\n",
      "\n",
      "  --seed SEED           Seed to use for random inputs\n",
      "  --val-range VAL_RANGE [VAL_RANGE ...]\n",
      "                        Range of values to generate in the data loader. To\n",
      "                        specify per-input ranges, use the format: --val-range\n",
      "                        <out_name>:[min,max]. If no input name is provided,\n",
      "                        the range is used for any inputs not explicitly\n",
      "                        specified. For example: --val-range [0,1] inp0:[2,50]\n",
      "                        inp1:[3.0,4.6]\n",
      "  --int-min INT_MIN     [DEPRECATED: Use --val-range] Minimum integer value\n",
      "                        for random integer inputs\n",
      "  --int-max INT_MAX     [DEPRECATED: Use --val-range] Maximum integer value\n",
      "                        for random integer inputs\n",
      "  --float-min FLOAT_MIN\n",
      "                        [DEPRECATED: Use --val-range] Minimum float value for\n",
      "                        random float inputs\n",
      "  --float-max FLOAT_MAX\n",
      "                        [DEPRECATED: Use --val-range] Maximum float value for\n",
      "                        random float inputs\n",
      "  --iterations NUM, --iters NUM\n",
      "                        Number of inference iterations for which to supply\n",
      "                        data\n",
      "  --load-inputs LOAD_INPUTS [LOAD_INPUTS ...], --load-input-data LOAD_INPUTS [LOAD_INPUTS ...]\n",
      "                        [EXPERIMENTAL] Path(s) to load inputs. The file(s)\n",
      "                        should be a JSON-ified List[Dict[str, numpy.ndarray]],\n",
      "                        i.e. a list where each element is the feed_dict for a\n",
      "                        single iteration. Other data loader options are\n",
      "                        ignored when this option is used\n",
      "  --data-loader-script DATA_LOADER_SCRIPT\n",
      "                        Path to a Python script that defines a function that\n",
      "                        loads input data. The function should take no\n",
      "                        arguments and return a generator or iterable that\n",
      "                        yields input data (Dict[str, np.ndarray]). When this\n",
      "                        option is specified, all other data loader arguments\n",
      "                        are ignored.\n",
      "  --data-loader-func-name DATA_LOADER_FUNC_NAME\n",
      "                        When using a data-loader-script, this specifies the\n",
      "                        name of the function that loads data. Defaults to\n",
      "                        `load_data`.\n",
      "\n",
      "TensorRT Builder Configuration:\n",
      "  Options for TensorRT Builder Configuration\n",
      "\n",
      "  --trt-min-shapes TRT_MIN_SHAPES [TRT_MIN_SHAPES ...]\n",
      "                        The minimum shapes the optimization profile(s) will\n",
      "                        support. Specify this option once for each profile. If\n",
      "                        not provided, inference-time input shapes are used.\n",
      "                        Format: --trt-min-shapes <input0>:[D0,D1,..,DN] ..\n",
      "                        <inputN>:[D0,D1,..,DN]\n",
      "  --trt-opt-shapes TRT_OPT_SHAPES [TRT_OPT_SHAPES ...]\n",
      "                        The shapes for which the optimization profile(s) will\n",
      "                        be most performant. Specify this option once for each\n",
      "                        profile. If not provided, inference-time input shapes\n",
      "                        are used. Format: --trt-opt-shapes\n",
      "                        <input0>:[D0,D1,..,DN] .. <inputN>:[D0,D1,..,DN]\n",
      "  --trt-max-shapes TRT_MAX_SHAPES [TRT_MAX_SHAPES ...]\n",
      "                        The maximum shapes the optimization profile(s) will\n",
      "                        support. Specify this option once for each profile. If\n",
      "                        not provided, inference-time input shapes are used.\n",
      "                        Format: --trt-max-shapes <input0>:[D0,D1,..,DN] ..\n",
      "                        <inputN>:[D0,D1,..,DN]\n",
      "  --tf32                Enable tf32 precision in TensorRT\n",
      "  --fp16                Enable fp16 precision in TensorRT\n",
      "  --int8                Enable int8 precision in TensorRT. If calibration is\n",
      "                        required but no calibration cache is provided, this\n",
      "                        option will cause TensorRT to run int8 calibration\n",
      "                        using the Polygraphy data loader to provide\n",
      "                        calibration data.\n",
      "  --no-strict-types     Disables strict types in TensorRT, allowing it to\n",
      "                        choose tactics outside the layer precision set.\n",
      "  --sparse-weights      Enable optimizations for sparse weights in TensorRT\n",
      "  --workspace BYTES     Amount of memory, in bytes, to allocate for the\n",
      "                        TensorRT builder's workspace. Optionally, use a `K`,\n",
      "                        `M`, or `G` suffix to indicate KiB, MiB, or GiB\n",
      "                        respectively.For example, `--workspace=16M` is\n",
      "                        equivalent to `--workspace=16777216`\n",
      "  --calibration-cache CALIBRATION_CACHE\n",
      "                        Path to load/save a calibration cache. Used to store\n",
      "                        calibration scales to speed up the process of int8\n",
      "                        calibration. If the provided path does not yet exist,\n",
      "                        int8 calibration scales will be calculated and written\n",
      "                        to it during engine building. If the provided path\n",
      "                        does exist, it will be read and int8 calibration will\n",
      "                        be skipped during engine building.\n",
      "  --calib-base-cls CALIBRATION_BASE_CLASS, --calibration-base-class CALIBRATION_BASE_CLASS\n",
      "                        The name of the calibration base class to use. For\n",
      "                        example, 'IInt8MinMaxCalibrator'.\n",
      "  --quantile QUANTILE   The quantile to use for IInt8LegacyCalibrator. Has no\n",
      "                        effect for other calibrator types.\n",
      "  --regression-cutoff REGRESSION_CUTOFF\n",
      "                        The regression cutoff to use for\n",
      "                        IInt8LegacyCalibrator. Has no effect for other\n",
      "                        calibrator types.\n",
      "  --timing-cache TIMING_CACHE\n",
      "                        Path to load/save tactic timing cache. Used to cache\n",
      "                        tactic timing information to speed up the engine\n",
      "                        building process. Existing caches will be appended to\n",
      "                        with any new timing information gathered.\n",
      "  --tactic-replay TACTIC_REPLAY\n",
      "                        [DEPRECATED - use --load/save-tactics] Path to\n",
      "                        load/save a tactic replay file. Used to record and\n",
      "                        replay tactics selected by TensorRT to provide\n",
      "                        deterministic engine builds. If the provided path does\n",
      "                        not yet exist, tactics will be recorded and written to\n",
      "                        it. If the provided path does exist, it will be read\n",
      "                        and used to replay previously recorded tactics.\n",
      "  --save-tactics SAVE_TACTICS\n",
      "                        Path to save a tactic replay file. Tactics selected by\n",
      "                        TensorRT will be recorded and stored at this location.\n",
      "  --load-tactics LOAD_TACTICS\n",
      "                        Path to load a tactic replay file. The tactics\n",
      "                        specified in the file will be used to override\n",
      "                        TensorRT's default selections.\n",
      "  --tactic-sources [TACTIC_SOURCES [TACTIC_SOURCES ...]]\n",
      "                        Tactic sources to enable. This controls which\n",
      "                        libraries (e.g. cudnn, cublas, etc.) TensorRT is\n",
      "                        allowed to load tactics from. Values come from the\n",
      "                        names of the values in the trt.TacticSource enum, and\n",
      "                        are case-insensitive. If no arguments are provided,\n",
      "                        e.g. '--tactic-sources', then all tactic sources are\n",
      "                        disabled.\n",
      "  --trt-config-script TRT_CONFIG_SCRIPT\n",
      "                        Path to a Python script that defines a function that\n",
      "                        creates a TensorRT IBuilderConfig. The function should\n",
      "                        take a builder and network as parameters and return a\n",
      "                        TensorRT builder configuration. When this option is\n",
      "                        specified, all other config arguments are ignored.\n",
      "  --trt-config-func-name TRT_CONFIG_FUNC_NAME\n",
      "                        When using a trt-config-script, this specifies the\n",
      "                        name of the function that creates the config. Defaults\n",
      "                        to `load_config`.\n",
      "  --trt-safety-restricted\n",
      "                        Enable safety scope checking in TensorRT\n",
      "  --use-dla             [EXPERIMENTAL] Use DLA as the default device type\n",
      "  --allow-gpu-fallback  [EXPERIMENTAL] Allow layers unsupported on the DLA to\n",
      "                        fall back to GPU. Has no effect if --dla is not set.\n",
      "\n",
      "TensorRT Plugin Loader:\n",
      "  Options for TensorRT Plugin Loader\n",
      "\n",
      "  --plugins PLUGINS [PLUGINS ...]\n",
      "                        Path(s) of plugin libraries to load\n",
      "\n",
      "TensorRT Network Loader:\n",
      "  Options for TensorRT Network Loader\n",
      "\n",
      "  --explicit-precision  Enable explicit precision mode\n",
      "  --trt-outputs TRT_OUTPUTS [TRT_OUTPUTS ...]\n",
      "                        Name(s) of TensorRT output(s). Using '--trt-outputs\n",
      "                        mark all' indicates that all tensors should be used as\n",
      "                        outputs\n",
      "  --trt-exclude-outputs TRT_EXCLUDE_OUTPUTS [TRT_EXCLUDE_OUTPUTS ...]\n",
      "                        [EXPERIMENTAL] Name(s) of TensorRT output(s) to unmark\n",
      "                        as outputs.\n",
      "  --trt-network-func-name TRT_NETWORK_FUNC_NAME\n",
      "                        When using a trt-network-script instead of other model\n",
      "                        types, this specifies the name of the function that\n",
      "                        loads the network. Defaults to `load_network`.\n"
     ]
    }
   ],
   "source": [
    "!polygraphy debug precision --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;14m[I] trt-runner-N0-01/17/23-15:07:36     | Activating and starting inference\u001b[0m\n",
      "[01/17/2023-15:07:37] [TRT] [W] parsers/onnx/onnx2trt_utils.cpp:368: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[01/17/2023-15:07:39] [TRT] [W] Output type must be INT32 for shape outputs\n",
      "[01/17/2023-15:07:39] [TRT] [W] Output type must be INT32 for shape outputs\n",
      "[01/17/2023-15:07:39] [TRT] [W] Output type must be INT32 for shape outputs\n",
      "[01/17/2023-15:07:39] [TRT] [W] Output type must be INT32 for shape outputs\n",
      "[I]     Configuring with profiles: [Profile().add(input_ids, min=[1, 128], opt=[1, 128], max=[1, 128]).add(attention_mask, min=[1, 128], opt=[1, 128], max=[1, 128]).add(token_type_ids, min=[1, 128], opt=[1, 128], max=[1, 128])]\n",
      "\u001b[38;5;14m[I] Building engine with configuration:\n",
      "    Workspace            | 16777216 bytes (16.00 MiB)\n",
      "    Precision            | TF32: False, FP16: False, INT8: False, Strict Types: False\n",
      "    Tactic Sources       | ['CUBLAS', 'CUBLAS_LT', 'CUDNN']\n",
      "    Safety Restricted    | False\n",
      "    Profiles             | 1 profile(s)\u001b[0m\n",
      "\u001b[38;5;10m[I] Finished engine building in 12.856 seconds\u001b[0m\n",
      "[I] Saving engine to polygraphy_debug.engine\n",
      "\u001b[38;5;11m[W] Input tensor: input_ids | Buffer dtype (int64) does not match expected input dtype (int32), attempting to cast. \u001b[0m\n",
      "\u001b[38;5;11m[W] Input tensor: attention_mask | Buffer dtype (int64) does not match expected input dtype (int32), attempting to cast. \u001b[0m\n",
      "\u001b[38;5;11m[W] Input tensor: token_type_ids | Buffer dtype (int64) does not match expected input dtype (int32), attempting to cast. \u001b[0m\n",
      "[I] trt-runner-N0-01/17/23-15:07:36    \n",
      "    ---- Inference Input(s) ----\n",
      "    {input_ids [dtype=int32, shape=(1, 128)],\n",
      "     attention_mask [dtype=int32, shape=(1, 128)],\n",
      "     token_type_ids [dtype=int32, shape=(1, 128)]}\n",
      "[I] trt-runner-N0-01/17/23-15:07:36    \n",
      "    ---- Inference Output(s) ----\n",
      "    {logits [dtype=float32, shape=(1, 128, 30522)]}\n",
      "\u001b[38;5;10m[I] trt-runner-N0-01/17/23-15:07:36     | Completed 1 iteration(s) in 7.83 ms | Average inference time: 7.83 ms.\u001b[0m\n",
      "[I] Saving inference results to trt_out.json\n",
      "\u001b[38;5;14m[I] Output Validation | Runners: ['trt-runner-N0-01/17/23-15:07:36']\u001b[0m\n",
      "\u001b[38;5;14m[I]     trt-runner-N0-01/17/23-15:07:36     | Validating output: logits (check_inf=True, check_nan=True)\u001b[0m\n",
      "[I]         mean=-4.2851, std-dev=2.4161, var=5.8374, median=-4.276, min=-20.737 at (0, 6, 21095), max=23.5 at (0, 7, 1012), avg-magnitude=4.3902\n",
      "\u001b[38;5;10m[I]         PASSED | Output: logits is valid\u001b[0m\n",
      "\u001b[38;5;10m[I]     PASSED | Output Validation\u001b[0m\n",
      "\u001b[38;5;10m[I] PASSED | Command: /opt/conda/bin/polygraphy run ./onnx/model_torch.onnx --trt --validate --save-engine polygraphy_debug.engine --save-results=trt_out.json --data-loader-script /workspace/examples/data_loader.py --trt-min-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128] --trt-opt-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128] --trt-max-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 不能加 --trt-outputs mark all, 但不加的话只有最后的输出\n",
    "!polygraphy run ./onnx/model_torch.onnx --trt --validate --save-engine polygraphy_debug.engine --save-results=trt_out.json \\\n",
    "    --data-loader-script /workspace/examples/data_loader.py \\\n",
    "    --trt-min-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128] \\\n",
    "    --trt-opt-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128] \\\n",
    "    --trt-max-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;14m[I] trt-runner-N0-01/18/23-16:25:28     | Activating and starting inference\u001b[0m\n",
      "[01/18/2023-16:25:29] [TRT] [W] parsers/onnx/onnx2trt_utils.cpp:368: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[01/18/2023-16:25:31] [TRT] [W] Output type must be INT32 for shape outputs\n",
      "[01/18/2023-16:25:31] [TRT] [W] Output type must be INT32 for shape outputs\n",
      "[01/18/2023-16:25:31] [TRT] [W] Output type must be INT32 for shape outputs\n",
      "[01/18/2023-16:25:31] [TRT] [W] Output type must be INT32 for shape outputs\n",
      "[I]     Configuring with profiles: [Profile().add(input_ids, min=[1, 128], opt=[1, 128], max=[1, 128]).add(attention_mask, min=[1, 128], opt=[1, 128], max=[1, 128]).add(token_type_ids, min=[1, 128], opt=[1, 128], max=[1, 128])]\n",
      "\u001b[38;5;14m[I] Building engine with configuration:\n",
      "    Workspace            | 16777216 bytes (16.00 MiB)\n",
      "    Precision            | TF32: False, FP16: True, INT8: False, Strict Types: False\n",
      "    Tactic Sources       | ['CUBLAS', 'CUBLAS_LT', 'CUDNN']\n",
      "    Safety Restricted    | False\n",
      "    Profiles             | 1 profile(s)\u001b[0m\n",
      "[01/18/2023-16:25:43] [TRT] [W] Weights [name=/bert/Constant_3_output_0 + (Unnamed Layer* 34) [Shuffle]]: Converted FP32 value in weights (either FP32 infinity or FP32 value outside FP16 range) to corresponding FP16 infinity. If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
      "[01/18/2023-16:25:52] [TRT] [W] Weights [name=/bert/Constant_3_output_0 + (Unnamed Layer* 34) [Shuffle]]: Converted FP32 value in weights (either FP32 infinity or FP32 value outside FP16 range) to corresponding FP16 infinity. If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
      "\u001b[38;5;10m[I] Finished engine building in 21.663 seconds\u001b[0m\n",
      "\u001b[38;5;11m[W] Input tensor: input_ids | Buffer dtype (int64) does not match expected input dtype (int32), attempting to cast. \u001b[0m\n",
      "\u001b[38;5;11m[W] Input tensor: attention_mask | Buffer dtype (int64) does not match expected input dtype (int32), attempting to cast. \u001b[0m\n",
      "\u001b[38;5;11m[W] Input tensor: token_type_ids | Buffer dtype (int64) does not match expected input dtype (int32), attempting to cast. \u001b[0m\n",
      "[I] trt-runner-N0-01/18/23-16:25:28    \n",
      "    ---- Inference Input(s) ----\n",
      "    {input_ids [dtype=int32, shape=(1, 128)],\n",
      "     attention_mask [dtype=int32, shape=(1, 128)],\n",
      "     token_type_ids [dtype=int32, shape=(1, 128)]}\n",
      "[I] trt-runner-N0-01/18/23-16:25:28    \n",
      "    ---- Inference Output(s) ----\n",
      "    {logits [dtype=float32, shape=(1, 128, 30522)]}\n",
      "\u001b[38;5;10m[I] trt-runner-N0-01/18/23-16:25:28     | Completed 1 iteration(s) in 6.555 ms | Average inference time: 6.555 ms.\u001b[0m\n",
      "\u001b[38;5;14m[I] onnxrt-runner-N0-01/18/23-16:25:28  | Activating and starting inference\u001b[0m\n",
      "[I] onnxrt-runner-N0-01/18/23-16:25:28 \n",
      "    ---- Inference Input(s) ----\n",
      "    {input_ids [dtype=int64, shape=(1, 128)],\n",
      "     attention_mask [dtype=int64, shape=(1, 128)],\n",
      "     token_type_ids [dtype=int64, shape=(1, 128)]}\n",
      "[I] onnxrt-runner-N0-01/18/23-16:25:28 \n",
      "    ---- Inference Output(s) ----\n",
      "    {logits [dtype=float32, shape=(1, 128, 30522)]}\n",
      "\u001b[38;5;10m[I] onnxrt-runner-N0-01/18/23-16:25:28  | Completed 1 iteration(s) in 13.25 ms | Average inference time: 13.25 ms.\u001b[0m\n",
      "\u001b[38;5;14m[I] Accuracy Comparison | trt-runner-N0-01/18/23-16:25:28 vs. onnxrt-runner-N0-01/18/23-16:25:28\u001b[0m\n",
      "\u001b[38;5;14m[I]     Comparing Output: 'logits' (dtype=float32, shape=(1, 128, 30522)) with 'logits' (dtype=float32, shape=(1, 128, 30522)) | Tolerance: [abs=0.1, rel=0.1] | Checking elemwise error\u001b[0m\n",
      "[I]         trt-runner-N0-01/18/23-16:25:28: logits | Stats: mean=nan, std-dev=nan, var=nan, median=nan, min=nan at (0, 0, 0), max=nan at (0, 0, 0), avg-magnitude=nan\n",
      "[I]         onnxrt-runner-N0-01/18/23-16:25:28: logits | Stats: mean=-4.2852, std-dev=2.4162, var=5.8378, median=-4.2762, min=-20.735 at (0, 6, 21095), max=23.5 at (0, 7, 1012), avg-magnitude=4.3904\n",
      "[I]         Error Metrics: logits\n",
      "[I]             Minimum Required Tolerance: elemwise error | [abs=0] OR [rel=0]\n",
      "[I]             Absolute Difference | Stats: mean=nan, std-dev=nan, var=nan, median=nan, min=nan at (0, 0, 0), max=nan at (0, 0, 0), avg-magnitude=nan\n",
      "[I]             Relative Difference | Stats: mean=nan, std-dev=nan, var=nan, median=nan, min=nan at (0, 0, 0), max=nan at (0, 0, 0), avg-magnitude=nan\n",
      "\u001b[38;5;10m[I]         PASSED | Difference is within tolerance (rel=0.1, abs=0.1)\u001b[0m\n",
      "\u001b[38;5;10m[I]     PASSED | All outputs matched | Outputs: ['logits']\u001b[0m\n",
      "\u001b[38;5;14m[I] Output Validation | Runners: ['trt-runner-N0-01/18/23-16:25:28', 'onnxrt-runner-N0-01/18/23-16:25:28']\u001b[0m\n",
      "\u001b[38;5;14m[I]     trt-runner-N0-01/18/23-16:25:28     | Validating output: logits (check_inf=True, check_nan=True)\u001b[0m\n",
      "[I]         mean=nan, std-dev=nan, var=nan, median=nan, min=nan at (0, 0, 0), max=nan at (0, 0, 0), avg-magnitude=nan\n",
      "\u001b[38;5;9m[E]         NaN Detected | One or more NaNs were encountered in this output\u001b[0m\n",
      "[I]         Note: Use -vv or set logging verbosity to EXTRA_VERBOSE to display locations of NaNs\n",
      "\u001b[38;5;9m[E]         Inf Detected | One or more non-finite values were encountered in this output\u001b[0m\n",
      "[I]         Note: Use -vv or set logging verbosity to EXTRA_VERBOSE to display non-finite values\n",
      "\u001b[38;5;9m[E]         FAILED | Errors detected in output: logits\u001b[0m\n",
      "\u001b[38;5;14m[I]     onnxrt-runner-N0-01/18/23-16:25:28  | Validating output: logits (check_inf=True, check_nan=True)\u001b[0m\n",
      "[I]         mean=-4.2852, std-dev=2.4162, var=5.8378, median=-4.2762, min=-20.735 at (0, 6, 21095), max=23.5 at (0, 7, 1012), avg-magnitude=4.3904\n",
      "\u001b[38;5;10m[I]         PASSED | Output: logits is valid\u001b[0m\n",
      "\u001b[38;5;9m[E]     FAILED | Output Validation\u001b[0m\n",
      "\u001b[38;5;9m[!] FAILED | Command: /opt/conda/bin/polygraphy run ./onnx/model_torch.onnx --trt --validate --onnxrt --atol 1e-1 --rtol 1e-1 --fp16 --data-loader-script /workspace/examples/data_loader.py --trt-min-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128] --trt-opt-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128] --trt-max-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 对比下两个框架的输出结果, trt 和 onnx\n",
    "!polygraphy run ./onnx/model_torch.onnx --trt --validate --onnxrt --atol 1e-1 --rtol 1e-1 \\\n",
    "    --fp16 \\\n",
    "    --data-loader-script /workspace/examples/data_loader.py \\\n",
    "    --trt-min-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128] \\\n",
    "    --trt-opt-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128] \\\n",
    "    --trt-max-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;9m[!] polygraphy_debug.engine already exists, refusing to overwrite.\n",
      "    Please specify a different path for the intermediate artifact with --intermediate-artifact\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!polygraphy debug precision ./onnx/model_torch.onnx --tf32 \\\n",
    "    --check polygraphy run polygraphy_debug.engine --trt --load-outputs onnx_out.json --abs 1e-1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
