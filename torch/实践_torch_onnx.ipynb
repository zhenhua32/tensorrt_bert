{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考来源\n",
    "\n",
    "- [Inference PyTorch Bert Model with ONNX Runtime on GPU](https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/tools/transformers/notebooks/PyTorch_Bert-Squad_OnnxRuntime_GPU.ipynb)\n",
    "- [transformers to onnx](https://huggingface.co/docs/transformers/v4.25.1/en/serialization#export-to-onnx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先必须安装依赖, onnxruntime 的 python 包也是分为 CPU 版和 GPU 版的.\n",
    "\n",
    "- onnxruntime\n",
    "- onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnxruntime-gpu in /opt/conda/lib/python3.8/site-packages (1.12.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.8/site-packages (from onnxruntime-gpu) (15.0.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.8/site-packages (from onnxruntime-gpu) (1.22.3)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.8/site-packages (from onnxruntime-gpu) (3.20.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from onnxruntime-gpu) (1.11.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from onnxruntime-gpu) (21.3)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.8/site-packages (from onnxruntime-gpu) (2.0.7)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.8/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->onnxruntime-gpu) (3.0.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->onnxruntime-gpu) (1.2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime-gpu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查 onnxruntime 环境已经安装正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "GPU\n",
      "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "print(onnxruntime.__version__)\n",
    "print(onnxruntime.get_device())\n",
    "print(onnxruntime.get_available_providers())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样的, 这次也是使用 BertForMaskedLM 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "from transformers import BertTokenizer\n",
    "enc = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "masked_sentences = ['Paris is the [MASK] of France.', \n",
    "                    'The primary [MASK] of the United States is English.', \n",
    "                    'A baseball game consists of at least nine [MASK].', \n",
    "                    'Topology is a branch of [MASK] concerned with the properties of geometric objects that remain unchanged under continuous transformations.']\n",
    "pos_masks = [4, 3, 9, 6]\n",
    "\n",
    "inputs = enc(masked_sentences, return_tensors=\"np\", padding='max_length', max_length=128)\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "origin_model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转换成 ONNX 模型\n",
    "\n",
    "可以直接使用 transformers.onnx 这个命令行转换模型, 我这里使用了特性头 `--feature=masked-lm`, 因为要和 BertForMaskedLM 类保持一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Framework not requested. Using torch to export to ONNX.\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using framework PyTorch: 1.12.0a0+8a1a93a\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "Validating ONNX model...\n",
      "\t-[✓] ONNX model output names match reference model ({'logits'})\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (3, 9, 30522) matches (3, 9, 30522)\n",
      "\t\t-[x] values not close enough (atol: 1e-05)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/onnx/__main__.py\", line 180, in <module>\n",
      "    main()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/onnx/__main__.py\", line 173, in main\n",
      "    validate_model_outputs(onnx_config, preprocessor, model, args.output, onnx_outputs, args.atol)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/onnx/convert.py\", line 472, in validate_model_outputs\n",
      "    raise ValueError(\n",
      "ValueError: Outputs values doesn't match between reference model and ONNX exported model: Got max absolute difference of: 0.00017833709716796875 for [ 0.39481845  0.5781618  -0.3123433  ... -2.2203553  -0.26061893\n",
      "  0.15988564] vs [ 0.39483854  0.57817936 -0.3123294  ... -2.2203958  -0.26063988\n",
      "  0.1598672 ]\n"
     ]
    }
   ],
   "source": [
    "# 本地转换模型还是有点报错的, 输出里提到绝对误差超过了 1e-5\n",
    "!python -m transformers.onnx --model=bert-base-uncased --feature=masked-lm onnx/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: 使用 torch.onnx.export 转换模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载 ONNX 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime import InferenceSession\n",
    "\n",
    "# 加载 ONNX 模型\n",
    "session = InferenceSession(\"onnx/model.onnx\", providers=[\"CUDAExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入:\n",
      "['input_ids', 'attention_mask', 'token_type_ids']\n",
      "[['batch', 'sequence'], ['batch', 'sequence'], ['batch', 'sequence']]\n",
      "['tensor(int64)', 'tensor(int64)', 'tensor(int64)']\n",
      "输出:\n",
      "['logits']\n",
      "[['batch', 'sequence', 30522]]\n",
      "['tensor(float)']\n"
     ]
    }
   ],
   "source": [
    "print(\"输入:\")\n",
    "print([x.name for x in session.get_inputs()])\n",
    "print([x.shape for x in session.get_inputs()])\n",
    "print([x.type for x in session.get_inputs()])\n",
    "\n",
    "print(\"输出:\")\n",
    "print([x.name for x in session.get_outputs()])\n",
    "print([x.shape for x in session.get_outputs()])\n",
    "print([x.type for x in session.get_outputs()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 128, 30522)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进行推理, 推理时注意, 模型的输入是 numpy array 类型\n",
    "outputs = session.run(output_names=[\"logits\"], input_feed=dict(inputs))\n",
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3007, 2653, 7202, 5597]\n",
      "Paris is the capital of France.\n",
      "The primary language of the United States is English.\n",
      "A baseball game consists of at least nine innings.\n",
      "Topology is a branch of mathematics concerned with the properties of geometric objects that remain unchanged under continuous transformations.\n"
     ]
    }
   ],
   "source": [
    "most_likely_token_ids = [numpy.argmax(outputs[0][i, pos, :]) for i, pos in enumerate(pos_masks)]\n",
    "print(most_likely_token_ids)\n",
    "unmasked_tokens = enc.decode(most_likely_token_ids).split(' ')\n",
    "unmasked_sentences = [masked_sentences[i].replace('[MASK]', token) for i, token in enumerate(unmasked_tokens)]\n",
    "for sentence in unmasked_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(3007), tensor(2653), tensor(7202), tensor(5597)]\n",
      "Paris is the capital of France.\n",
      "The primary language of the United States is English.\n",
      "A baseball game consists of at least nine innings.\n",
      "Topology is a branch of mathematics concerned with the properties of geometric objects that remain unchanged under continuous transformations.\n"
     ]
    }
   ],
   "source": [
    "# 和原始模型对照下\n",
    "inputs_pt = enc(masked_sentences, return_tensors=\"pt\", padding='max_length', max_length=128)\n",
    "outputs = origin_model(**inputs_pt)\n",
    "\n",
    "most_likely_token_ids = [torch.argmax(outputs[0][i, pos, :]) for i, pos in enumerate(pos_masks)]\n",
    "print(most_likely_token_ids)\n",
    "unmasked_tokens = enc.decode(most_likely_token_ids).split(' ')\n",
    "unmasked_sentences = [masked_sentences[i].replace('[MASK]', token) for i, token in enumerate(unmasked_tokens)]\n",
    "for sentence in unmasked_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e2a1ac0cd441cd5e6071952e5fb90a282373ff6bf90167c932fd3386a58db77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
