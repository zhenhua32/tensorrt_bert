{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转换模型\n",
    "\n",
    "TODO: 没有动态的维度支持, 有个报错, 只有将 batch_size 设置为 1\n",
    "\n",
    "```bash\n",
    "[01/04/2023-04:21:30] [TRT] [E] 10: [optimizer.cpp::computeCosts::2011] Error Code 10: Internal Error (Could not find any implementation for node {ForeignNode[bert.embeddings.position_embeddings.weight.../cls/predictions/decoder/Add]}.)\n",
    "[01/04/2023-04:21:30] [TRT] [E] 2: [builder.cpp::buildSerializedNetwork::609] Error Code 2: Internal Error (Assertion enginePtr != nullptr failed. )\n",
    "```\n",
    "\n",
    "```bash\n",
    "!polygraphy convert ./onnx/model.onnx --convert-to trt -o ./onnx/model.trt --model-type onnx \\\n",
    "\t--trt-min-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128] \\\n",
    "\t--trt-opt-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128] \\\n",
    "\t--trt-max-shapes input_ids:[1,128] attention_mask:[1,128] token_type_ids:[1,128] \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/NVIDIA/TensorRT/tree/main/tools/Polygraphy#command-line-toolkit\n",
    "\n",
    "polygraphy 工具在 TensorRT 仓库下, 如果你安装了 tensorrt 的 python 包, 应该就能找到\n",
    "\n",
    "/opt/conda/bin/polygraphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "from tensorrt.tensorrt import Logger, Runtime\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"./transformer-deploy/src/\")\n",
    "\n",
    "from transformer_deploy.backends.trt_utils import build_engine, load_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_logger: Logger = trt.Logger(trt.Logger.ERROR)\n",
    "runtime: Runtime = trt.Runtime(trt_logger)\n",
    "profile_index = 0\n",
    "max_seq_len = 128\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorrt_model = load_engine(\n",
    "    runtime=runtime,\n",
    "    engine_file_path=\"./onnx/model.trt\",\n",
    "    profile_index=profile_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "from transformers import BertTokenizer\n",
    "enc = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "masked_sentences = [\n",
    "    'Paris is the [MASK] of France.', \n",
    "    # 'The primary [MASK] of the United States is English.', \n",
    "    # 'A baseball game consists of at least nine [MASK].', \n",
    "    # 'Topology is a branch of [MASK] concerned with the properties of geometric objects that remain unchanged under continuous transformations.'\n",
    "]\n",
    "pos_masks = [\n",
    "    4, \n",
    "    # 3, \n",
    "    # 9, \n",
    "    # 6\n",
    "]\n",
    "\n",
    "inputs = enc(masked_sentences, return_tensors=\"pt\", padding='max_length', max_length=128, truncation=True)\n",
    "print(inputs.keys())\n",
    "\n",
    "# 我就说这个坑好像哪里踩过, 这个顺序有点坑的\n",
    "new_inputs = dict()\n",
    "for key in ['input_ids', 'attention_mask', 'token_type_ids']:\n",
    "    new_inputs[key] = inputs[key]\n",
    "# TODO: 还是不行, 输出的结果不对. 好像每个输出的结果都是一样的\n",
    "result = tensorrt_model(new_inputs)\n",
    "print(type(result))\n",
    "print(len(result))\n",
    "print(result[0].shape)\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_likely_token_ids = [numpy.argmax(result[0].cpu().numpy()[i, pos, :]) for i, pos in enumerate(pos_masks)]\n",
    "print(most_likely_token_ids)\n",
    "unmasked_tokens = enc.decode(most_likely_token_ids).split(' ')\n",
    "unmasked_sentences = [masked_sentences[i].replace('[MASK]', token) for i, token in enumerate(unmasked_tokens)]\n",
    "for sentence in unmasked_sentences:\n",
    "    print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e2a1ac0cd441cd5e6071952e5fb90a282373ff6bf90167c932fd3386a58db77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
